{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613f06a2-a6a0-4d42-b1bb-1bc8c30fa45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 10:19:45.025134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:root:TensorFlow Decision Forests 1.9.0 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.16.2 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2f35dbd-1ce3-4f5d-be1b-90d2f41fc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/processed/train_data.csv', keep_default_na=False)\n",
    "test = pd.read_csv('../data/processed/test_data.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a0a648-54c4-4f1b-8481-1c716b6896c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split input and output\n",
    "X_train=train.drop(['SalePrice'], axis=1)\n",
    "y_train= train['SalePrice']\n",
    "\n",
    "X_test=test.drop(['SalePrice'], axis=1)\n",
    "y_test= test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308c1056-ff4e-4332-bdec-34575a6ee19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding - convert categorical columns to numerical for linear regression. \n",
    "#there was an error with vanishing columns in test. This fixes it. \n",
    "X_train_one_hot = pd.get_dummies(X_train, drop_first=True) \n",
    "cols = X_train_one_hot.columns.tolist()\n",
    "X_test_one_hot = pd.get_dummies(X_test, drop_first=True) \n",
    "X_test_one_hot = X_test_one_hot.reindex(columns=cols).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a14c25-846b-4a08-a161-7291a88e9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cc16b2-b4d5-4462-ae53-7d132417cc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(fit_intercept=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit_intercept=False is needed as collinearity of one hot encoding, first row has to be dropped. \n",
    "reg = linear_model.LinearRegression(fit_intercept=False)\n",
    "reg.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a11675-5ff1-49a2-8a0c-4c77baea66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict sales price on test set\n",
    "predictions_lm = reg.predict(X_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5aa535a-48bf-45e7-891f-603ed00e0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply inverse transformation to bring predictions back to the original scale\n",
    "predictions_lm = np.exp(predictions_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "721a57be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for Linear Regression Model: 5600584.853498658\n"
     ]
    }
   ],
   "source": [
    "#RMSE \n",
    "rmse_lm = np.sqrt(mean_squared_error(np.exp(y_test), predictions_lm))\n",
    "print(f'Root Mean Squared Error for Linear Regression Model: {rmse_lm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1bfe822-4c3a-44a9-8723-5b7c41a0bc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensorflow_decision_forests.keras.RandomForestModel,\n",
       " tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n",
       " tensorflow_decision_forests.keras.CartModel,\n",
       " tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensorflow Decision Forest Models (TF-DF)\n",
    "tfdf.keras.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0a3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe into a TensorFlow dataset\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"SalePrice\", task = tfdf.keras.Task.REGRESSION)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=\"SalePrice\", task = tfdf.keras.Task.REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b196048-d9df-4411-a207-d8eb950c1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f96763e-d63d-4074-8646-b12861b7b638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_decision_forests.component.tuner.tuner.SearchSpace at 0x317de7150>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomSearch tuner\n",
    "tuner_rf = tfdf.tuner.RandomSearch(num_trials=20)\n",
    "\n",
    "tuner_rf.choice(\"num_trees\", [100, 200, 500])\n",
    "tuner_rf.choice(\"max_depth\", [-1, 10, 30])\n",
    "tuner_rf.choice(\"min_examples\", [2, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65dbbf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmp31rk11v4 as temporary training directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method InferenceCoreModel.compile of <tensorflow_decision_forests.keras.RandomForestModel object at 0x323e24a50>>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION, tuner=tuner_rf)\n",
    "model_rf.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "effb2b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.330494. Found 1165 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-15 14:06:09.0896 EST kernel.cc:1233] Loading model from path /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmp31rk11v4/model/ with prefix 97b7341b317a4e0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:39.146081\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-15 14:06:09.3536 EST decision_forest.cc:734] Model loaded with 500 root(s), 218842 node(s), and 80 input feature(s).\n",
      "[INFO 25-01-15 14:06:09.3537 EST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 25-01-15 14:06:09.3537 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x32007fe20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x32007fe20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x317beb890>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "059223b4-113a-43ca-b423-8db7aa7ef195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score              -0.152176\n",
       "evaluation_time    31.007573\n",
       "best                    True\n",
       "num_trees                500\n",
       "max_depth                 10\n",
       "min_examples               2\n",
       "Name: 17, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_logs_rf = model_rf.make_inspector().tuning_logs()\n",
    "# Best hyper-parameters.\n",
    "tuning_logs_rf[tuning_logs_rf.best].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2354ac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "model_rf.compile(metrics=[\"accuracy\"])\n",
    "print(model_rf.evaluate(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "981e09c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(num_examples=1165, accuracy=None, loss=None, rmse=0.15217643958890595, ndcg=None, aucs=None, auuc=None, qini=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector = model_rf.make_inspector()\n",
    "inspector.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6909f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note this RMSE is on the logarmithic data, not the actual data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf61b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x3208e0180> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x3208e0180> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n"
     ]
    }
   ],
   "source": [
    "#calculate the actual RMSE\n",
    "predictions_rf_log = model_rf.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "155e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf=np.exp(predictions_rf_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04dae43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for TF-DF Random Forest: 34789.153809252544\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = np.sqrt(mean_squared_error(np.exp(y_test), predictions_rf))\n",
    "print(f'Root Mean Squared Error for TF-DF Random Forest: {rmse_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38a60581-41ab-453a-9439-97721c7a9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostedTreesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d81fa9e-3645-4ba3-a804-66fe0fc788d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_decision_forests.component.tuner.tuner.SearchSpace at 0x313d41450>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomSearch tuner\n",
    "tuner_gb = tfdf.tuner.RandomSearch(num_trials=10)\n",
    "\n",
    "tuner_gb.choice(\"num_trees\", [50, 100, 200, 500, 1000])\n",
    "tuner_gb.choice(\"shrinkage\", [0.01, 0.05, 0.1, 0.3, 0.5])\n",
    "tuner_gb.choice(\"max_depth\", [3, 4, 5, 6, 8, 10])\n",
    "tuner_gb.choice(\"min_examples\", [2, 5, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4664ee2-e903-430a-90b6-01021c916065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpy0om9j_q as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 25-01-15 14:06:16.9609 EST gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 25-01-15 14:06:16.9618 EST gradient_boosted_trees.cc:1851] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 25-01-15 14:06:16.9618 EST gradient_boosted_trees.cc:1865] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.610287. Found 1165 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:09.814821\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-15 14:06:27.3915 EST kernel.cc:1233] Loading model from path /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpy0om9j_q/model/ with prefix 280fd0106ec14077\n",
      "[INFO 25-01-15 14:06:27.3924 EST abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 25-01-15 14:06:27.3924 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Gradient Boosted Trees Regression model\n",
    "model_gb_regressor = tfdf.keras.GradientBoostedTreesModel(\n",
    "    task=tfdf.keras.Task.REGRESSION,\n",
    "    tuner=tuner_gb\n",
    ")\n",
    "\n",
    "model_gb_regressor.fit(train_ds)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e943537-2ae9-414b-9629-005510e635cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score             -0.159583\n",
       "evaluation_time     1.08091\n",
       "best                   True\n",
       "num_trees                50\n",
       "shrinkage               0.3\n",
       "max_depth                 4\n",
       "min_examples              2\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_logs_gb = model_gb_regressor.make_inspector().tuning_logs()\n",
    "# Best hyper-parameters.\n",
    "tuning_logs_gb[tuning_logs_gb.best].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27a411a2-4a98-4c61-b93d-f30a8550183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test dataset\n",
    "predictions_gb_log = model_gb_regressor.predict(test_ds)\n",
    "\n",
    "# Reverse log transformation for predictions\n",
    "predictions_gb = np.exp(predictions_gb_log)\n",
    "\n",
    "# Reverse the log transformation for true variable\n",
    "y=test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aab04474-f9d1-4b53-bd18-16e8d3d47356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for TF-DF Gradient Boosted Trees: 28356.90959290289\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE and evaluate model performance\n",
    "rmse_gb = np.sqrt(mean_squared_error(np.exp(y), predictions_gb))\n",
    "print(f'Root Mean Squared Error for TF-DF Gradient Boosted Trees: {rmse_gb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aea9f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4a80b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpvu1bv5yz as temporary training directory\n",
      "Reading training dataset...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x313b9e980> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x313b9e980> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.348830. Found 1165 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.031573\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-15 14:07:15.7906 EST kernel.cc:1233] Loading model from path /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpvu1bv5yz/model/ with prefix 12a7910b92384c1c\n",
      "[INFO 25-01-15 14:07:15.7910 EST decision_forest.cc:734] Model loaded with 1 root(s), 101 node(s), and 21 input feature(s).\n",
      "[INFO 25-01-15 14:07:15.7910 EST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 25-01-15 14:07:15.7911 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x317c0f9c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x317c0f9c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x346fe1650>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model_cm_regression = tfdf.keras.CartModel(task=tfdf.keras.Task.REGRESSION)\n",
    "model_cm_regression.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7618be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the same dataset (or test set)\n",
    "predictions_log_cm = model_cm_regression.predict(test_ds)\n",
    "\n",
    "# Reverse the log transformation (use np.exp to get the original scale)\n",
    "predictions_cm = np.exp(predictions_log_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28eaba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for TF-DF Cart Model: 45776.47002119163\n"
     ]
    }
   ],
   "source": [
    "rmse_cm = np.sqrt(mean_squared_error(np.exp(y), predictions_cm))\n",
    "print(f'Root Mean Squared Error for TF-DF Cart Model: {rmse_cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7df3139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic sklearn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b307ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(oob_score=True, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(oob_score=True, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0, oob_score=True)\n",
    "regressor.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bcc60aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_regressor_log = regressor.predict(X_test_one_hot)\n",
    "predictions_regressor = np.exp(predictions_regressor_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14cb68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for sklearn Random Forest: 1127542967.1339123\n"
     ]
    }
   ],
   "source": [
    "mse_rf = mean_squared_error(np.exp(y_test), predictions_regressor)\n",
    "print(f'Mean Squared Error for sklearn Random Forest: {mse_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b0513b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x347765790>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig,ax = plt.subplots(figsize=(6,6))\n",
    "    ax.set_title('House price predictions',fontsize=20)\n",
    "    ax.set_ylabel('predicted',fontsize=12)\n",
    "    ax.set_xlabel('actual',fontsize=12)\n",
    "    ax.scatter(np.exp(y_test), predictions_regressor,label='Random Forest')\n",
    "    ax.scatter(np.exp(y), predictions_rf,label='TF-DF random forest')\n",
    "    ax.scatter(np.exp(y), predictions_cm,label='Cart model')\n",
    "    ax.scatter(np.exp(y), predictions_gb,label='GradientBoostedTreesModel')\n",
    "    ax.scatter(np.exp(y_test), predictions_lm,label='Linear model')\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3ccbaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map model names to their corresponding classes\n",
    "models = {\n",
    "    \"gradient_boosted_trees\": tfdf.keras.GradientBoostedTreesModel,\n",
    "    \"random_forest\": tfdf.keras.RandomForestModel\n",
    "}\n",
    "\n",
    "# Define model hyperparameter configurations\n",
    "params = {\n",
    "    \"gradient_boosted_trees\": {\n",
    "        \"num_trees\": [50, 100, 200, 500, 1000],\n",
    "        \"shrinkage\": [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "        \"max_depth\": [3, 4, 5, 6, 8, 10],\n",
    "        \"min_examples\": [2, 5, 10, 15]\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"num_trees\": [100, 200, 500],\n",
    "        \"max_depth\": [-1, 10, 30],\n",
    "        \"min_examples\": [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "num_trials = {\n",
    "    \"gradient_boosted_trees\": 10,\n",
    "    \"random_forest\": 20\n",
    "}\n",
    "\n",
    "# Placeholder to store model output\n",
    "output_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4db13248-83ee-4b6c-9ae8-2dc81ced5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpr4zjriby as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 25-01-15 14:08:34.9304 EST gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 25-01-15 14:08:34.9304 EST gradient_boosted_trees.cc:1851] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 25-01-15 14:08:34.9304 EST gradient_boosted_trees.cc:1865] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x313b9e980> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x313b9e980> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.328653. Found 1165 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:09.754847\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-15 14:08:45.0182 EST kernel.cc:1233] Loading model from path /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpr4zjriby/model/ with prefix 6dd44884c81a43d3\n",
      "[INFO 25-01-15 14:08:45.0191 EST abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 25-01-15 14:08:45.0191 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x347938ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x347938ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "Use /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpkt7aq3lh as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.297603. Found 1165 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-15 14:09:24.1456 EST kernel.cc:1233] Loading model from path /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpkt7aq3lh/model/ with prefix cb7a7e03941141f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:38.553663\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-15 14:09:24.4099 EST decision_forest.cc:734] Model loaded with 500 root(s), 218842 node(s), and 80 input feature(s).\n",
      "[INFO 25-01-15 14:09:24.4100 EST abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 25-01-15 14:09:24.4100 EST kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 88ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train each model\n",
    "for model_name, config in params.items():\n",
    "    output_logs.append(f\"Training and tuning {model_name}...\")\n",
    "\n",
    "    num_trial = num_trials.get(model_name, 10)  # Get the number of trials for the model\n",
    "    tuner = tfdf.tuner.RandomSearch(num_trials=num_trial)\n",
    "    \n",
    "    # Loop through the configuration dictionary and set the hyperparameters\n",
    "    for param, values in config.items():\n",
    "        tuner.choice(param, values)\n",
    "    \n",
    "    model_class = models[model_name]  # Get the corresponding model class\n",
    "    model = model_class(task=tfdf.keras.Task.REGRESSION, tuner=tuner)\n",
    "    \n",
    "    model.fit(train_ds)\n",
    "\n",
    "    #get best parameters\n",
    "    tuning_logs = model.make_inspector().tuning_logs()\n",
    "    best_params = tuning_logs[tuning_logs.best].iloc[0]\n",
    "    \n",
    "    predictions_log = model.predict(test_ds)\n",
    "    y_pred = np.exp(predictions_log)\n",
    "    y_true = np.exp(y_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    output_logs.append(f\"Best parameters for {model_name}: {best_params}\")\n",
    "    output_logs.append(f\"Best RMSE for {model_name}: {rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d866b29-3e6c-4607-a580-1270ee823bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning gradient_boosted_trees...\n",
      "Best parameters for gradient_boosted_trees: score             -0.159583\n",
      "evaluation_time    1.070461\n",
      "best                   True\n",
      "num_trees                50\n",
      "shrinkage               0.3\n",
      "max_depth                 4\n",
      "min_examples              2\n",
      "Name: 3, dtype: object\n",
      "Best RMSE for gradient_boosted_trees: 28356.909593\n",
      "Training and tuning random_forest...\n",
      "Best parameters for random_forest: score              -0.152176\n",
      "evaluation_time    30.739577\n",
      "best                    True\n",
      "num_trees                500\n",
      "max_depth                 10\n",
      "min_examples               2\n",
      "Name: 17, dtype: object\n",
      "Best RMSE for random_forest: 34789.153809\n"
     ]
    }
   ],
   "source": [
    "for log in output_logs:\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a936f9-8fcf-44f6-b78e-f97a6a3c9990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed7d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4520bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting has the lowest RMSE. That will be used for the final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80832a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge train_ds and test_ds\n",
    "total_ds=pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e3404a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ds = tfdf.keras.pd_dataframe_to_tf_dataset(total_ds, label=\"SalePrice\", task = tfdf.keras.Task.REGRESSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a7fca81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_decision_forests.component.tuner.tuner.SearchSpace at 0x13d26ba10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a RandomSearch tuner\n",
    "tuner_gb = tfdf.tuner.RandomSearch(num_trials=10)\n",
    "\n",
    "tuner_gb.choice(\"num_trees\", [50, 100, 200, 500, 1000])\n",
    "tuner_gb.choice(\"shrinkage\", [0.01, 0.05, 0.1, 0.3, 0.5])\n",
    "tuner_gb.choice(\"max_depth\", [3, 4, 5, 6, 8, 10])\n",
    "tuner_gb.choice(\"min_examples\", [2, 5, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b9f6fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/tmpaed_v44c as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 25-01-16 10:33:07.9384 GMT gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 25-01-16 10:33:07.9384 GMT gradient_boosted_trees.cc:1851] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 25-01-16 10:33:07.9384 GMT gradient_boosted_trees.cc:1865] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:05.191709. Found 1457 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:12.593861\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 25-01-16 10:33:25.7468 GMT kernel.cc:1233] Loading model from path /var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/tmpaed_v44c/model/ with prefix b5c5379621584ccb\n",
      "[INFO 25-01-16 10:33:25.7553 GMT quick_scorer_extended.cc:911] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "[INFO 25-01-16 10:33:25.7562 GMT abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 25-01-16 10:33:25.7562 GMT kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Gradient Boosted Trees Regression model\n",
    "model_gb_regressor = tfdf.keras.GradientBoostedTreesModel(\n",
    "    task=tfdf.keras.Task.REGRESSION,\n",
    "    tuner=tuner_gb\n",
    ")\n",
    "\n",
    "model_gb_regressor.fit(total_ds)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54f63c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score             -0.158382\n",
       "evaluation_time    3.302366\n",
       "best                   True\n",
       "num_trees               500\n",
       "shrinkage              0.05\n",
       "max_depth                 4\n",
       "min_examples             10\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_logs_gb = model_gb_regressor.make_inspector().tuning_logs()\n",
    "# Best hyper-parameters.\n",
    "tuning_logs_gb[tuning_logs_gb.best].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea347e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load testing data set \n",
    "testing = pd.read_csv('../data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f8ea30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.fillna('None', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b5a1f2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:105\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:514\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    511\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    515\u001b[0m     element,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 0        468.0\n1        923.0\n2        791.0\n3        602.0\n4        263.0\n         ...  \n1454       0.0\n1455     252.0\n1456    1224.0\n1457     337.0\n1458     758.0\nName: BsmtFinSF1, Length: 1459, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testing \u001b[38;5;241m=\u001b[39m tfdf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpd_dataframe_to_tf_dataset(testing, task \u001b[38;5;241m=\u001b[39m tfdf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mTask\u001b[38;5;241m.\u001b[39mREGRESSION)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py:1184\u001b[0m, in \u001b[0;36mpd_dataframe_to_tf_dataset\u001b[0;34m(dataframe, label, task, max_num_classes, in_place, fix_feature_names, weight, batch_size)\u001b[0m\n\u001b[1;32m   1180\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is only supported if the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is also provided\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1183\u001b[0m     )\n\u001b[0;32m-> 1184\u001b[0m   tf_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(\u001b[38;5;28mdict\u001b[39m(dataframe))\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# The batch size does not impact the training of TF-DF.\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:826\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m from_tensor_slices_op\u001b[38;5;241m.\u001b[39m_from_tensor_slices(tensors, name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _TensorSliceDataset(tensors, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mnormalize_element(element)\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:110\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 110\u001b[0m       ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m i))\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m    714\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m    715\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m conversion_func(value, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname, as_ref\u001b[38;5;241m=\u001b[39mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m constant_op\u001b[38;5;241m.\u001b[39mconstant(v, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    277\u001b[0m                         allow_broadcast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "testing = tfdf.keras.pd_dataframe_to_tf_dataset(testing, task = tfdf.keras.Task.REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7551201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac16fba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py\", line 486, in run_step  *\n        outputs = model.predict_step(data)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 2377, in predict_step  *\n        return self(x, training=False)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 565, in error_handler  *\n        del filtered_tb\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 588, in __call__  *\n        return super().__call__(*args, **kwargs)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 560, in error_handler  *\n        filtered_tb = _process_traceback_frames(e.__traceback__)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filel9puqnkl.py\", line 162, in error_handler  **\n        raise ag__.converted_call(ag__.ld(new_e).with_traceback, (ag__.ld(e).__traceback__,), None, fscope_1) from None\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filel9puqnkl.py\", line 34, in error_handler\n        retval__1 = ag__.converted_call(ag__.ld(fn), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file3lfsir1x.py\", line 232, in tf__call\n        ag__.if_stmt(ag__.ld(self)._semantics is None, if_body_8, else_body_8, get_state_11, set_state_11, ('do_return', 'retval_'), 2)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file3lfsir1x.py\", line 43, in else_body_8\n        normalized_inputs = ag__.converted_call(ag__.ld(self)._build_normalized_inputs, (ag__.ld(inputs),), None, fscope)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filey80y390p.py\", line 99, in tf___build_normalized_inputs\n        normalized_semantic_inputs = ag__.converted_call(ag__.ld(tf_core).normalize_inputs, (ag__.ld(semantic_inputs),), dict(categorical_integer_offset_correction=ag__.not_(ag__.ld(self)._advanced_arguments.disable_categorical_integer_offset_correction)), fscope)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 205, in tf__normalize_inputs\n        ag__.for_stmt(ag__.converted_call(ag__.ld(inputs).items, (), None, fscope), None, loop_body, get_state_13, set_state_13, (), {'iterate_names': '(key, semantic_tensor)'})\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 201, in loop_body\n        ag__.if_stmt(ag__.ld(semantic_tensor).semantic in [ag__.ld(Semantic).NUMERICAL, ag__.ld(Semantic).DISCRETIZED_NUMERICAL], if_body_12, else_body_12, get_state_12, set_state_12, ('normalized_inputs[key]',), 1)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 60, in if_body_12\n        ag__.if_stmt(ag__.ld(semantic_tensor).tensor.dtype in ag__.ld(FlexibleNumericalTypes), if_body, else_body, get_state, set_state, (), 0)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 59, in else_body\n        raise ag__.converted_call(ag__.ld(ValueError), (ag__.converted_call('Non supported tensor dtype {} for semantic {} of feature {}'.format, (ag__.ld(semantic_tensor).tensor.dtype, ag__.ld(semantic_tensor).semantic, ag__.ld(key)), None, fscope),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'gradient_boosted_trees_model_1' (type GradientBoostedTreesModel).\n    \n    in user code:\n    \n        File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py\", line 672, in call  *\n            normalized_inputs = self._build_normalized_inputs(inputs)\n        File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py\", line 634, in _build_normalized_inputs  *\n            normalized_semantic_inputs = tf_core.normalize_inputs(\n        File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/tensorflow/core_inference.py\", line 220, in normalize_inputs  *\n            raise ValueError(\n    \n        ValueError: Non supported tensor dtype <dtype: 'string'> for semantic Semantic.NUMERICAL of feature LotFrontage\n    \n    \n    Call arguments received by layer 'gradient_boosted_trees_model_1' (type GradientBoostedTreesModel):\n      • inputs={'Id': 'tf.Tensor(shape=(None,), dtype=int64)', 'MSSubClass': 'tf.Tensor(shape=(None,), dtype=int64)', 'MSZoning': 'tf.Tensor(shape=(None,), dtype=string)', 'LotFrontage': 'tf.Tensor(shape=(None,), dtype=string)', 'LotArea': 'tf.Tensor(shape=(None,), dtype=int64)', 'Street': 'tf.Tensor(shape=(None,), dtype=string)', 'Alley': 'tf.Tensor(shape=(None,), dtype=string)', 'LotShape': 'tf.Tensor(shape=(None,), dtype=string)', 'LandContour': 'tf.Tensor(shape=(None,), dtype=string)', 'Utilities': 'tf.Tensor(shape=(None,), dtype=string)', 'LotConfig': 'tf.Tensor(shape=(None,), dtype=string)', 'LandSlope': 'tf.Tensor(shape=(None,), dtype=string)', 'Neighborhood': 'tf.Tensor(shape=(None,), dtype=string)', 'Condition1': 'tf.Tensor(shape=(None,), dtype=string)', 'Condition2': 'tf.Tensor(shape=(None,), dtype=string)', 'BldgType': 'tf.Tensor(shape=(None,), dtype=string)', 'HouseStyle': 'tf.Tensor(shape=(None,), dtype=string)', 'OverallQual': 'tf.Tensor(shape=(None,), dtype=int64)', 'OverallCond': 'tf.Tensor(shape=(None,), dtype=int64)', 'YearBuilt': 'tf.Tensor(shape=(None,), dtype=int64)', 'YearRemodAdd': 'tf.Tensor(shape=(None,), dtype=int64)', 'RoofStyle': 'tf.Tensor(shape=(None,), dtype=string)', 'RoofMatl': 'tf.Tensor(shape=(None,), dtype=string)', 'Exterior1st': 'tf.Tensor(shape=(None,), dtype=string)', 'Exterior2nd': 'tf.Tensor(shape=(None,), dtype=string)', 'MasVnrType': 'tf.Tensor(shape=(None,), dtype=string)', 'MasVnrArea': 'tf.Tensor(shape=(None,), dtype=string)', 'ExterQual': 'tf.Tensor(shape=(None,), dtype=string)', 'ExterCond': 'tf.Tensor(shape=(None,), dtype=string)', 'Foundation': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtQual': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtCond': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtExposure': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinType1': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinSF1': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinType2': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinSF2': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtUnfSF': 'tf.Tensor(shape=(None,), dtype=string)', 'TotalBsmtSF': 'tf.Tensor(shape=(None,), dtype=string)', 'Heating': 'tf.Tensor(shape=(None,), dtype=string)', 'HeatingQC': 'tf.Tensor(shape=(None,), dtype=string)', 'CentralAir': 'tf.Tensor(shape=(None,), dtype=string)', 'Electrical': 'tf.Tensor(shape=(None,), dtype=string)', '1stFlrSF': 'tf.Tensor(shape=(None,), dtype=int64)', '2ndFlrSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'LowQualFinSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'GrLivArea': 'tf.Tensor(shape=(None,), dtype=int64)', 'BsmtFullBath': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtHalfBath': 'tf.Tensor(shape=(None,), dtype=string)', 'FullBath': 'tf.Tensor(shape=(None,), dtype=int64)', 'HalfBath': 'tf.Tensor(shape=(None,), dtype=int64)', 'BedroomAbvGr': 'tf.Tensor(shape=(None,), dtype=int64)', 'KitchenAbvGr': 'tf.Tensor(shape=(None,), dtype=int64)', 'KitchenQual': 'tf.Tensor(shape=(None,), dtype=string)', 'TotRmsAbvGrd': 'tf.Tensor(shape=(None,), dtype=int64)', 'Functional': 'tf.Tensor(shape=(None,), dtype=string)', 'Fireplaces': 'tf.Tensor(shape=(None,), dtype=int64)', 'FireplaceQu': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageType': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageYrBlt': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageFinish': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageCars': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageArea': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageQual': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageCond': 'tf.Tensor(shape=(None,), dtype=string)', 'PavedDrive': 'tf.Tensor(shape=(None,), dtype=string)', 'WoodDeckSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'OpenPorchSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'EnclosedPorch': 'tf.Tensor(shape=(None,), dtype=int64)', '3SsnPorch': 'tf.Tensor(shape=(None,), dtype=int64)', 'ScreenPorch': 'tf.Tensor(shape=(None,), dtype=int64)', 'PoolArea': 'tf.Tensor(shape=(None,), dtype=int64)', 'PoolQC': 'tf.Tensor(shape=(None,), dtype=string)', 'Fence': 'tf.Tensor(shape=(None,), dtype=string)', 'MiscFeature': 'tf.Tensor(shape=(None,), dtype=string)', 'MiscVal': 'tf.Tensor(shape=(None,), dtype=int64)', 'MoSold': 'tf.Tensor(shape=(None,), dtype=int64)', 'YrSold': 'tf.Tensor(shape=(None,), dtype=int64)', 'SaleType': 'tf.Tensor(shape=(None,), dtype=string)', 'SaleCondition': 'tf.Tensor(shape=(None,), dtype=string)'}\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions on test dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions_gb_log \u001b[38;5;241m=\u001b[39m model_gb_regressor\u001b[38;5;241m.\u001b[39mpredict(testing)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Reverse log transformation for predictions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions_gb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(predictions_gb_log)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file7g0mqir6.py:43\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function_trained\u001b[0;34m(iterator, model)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(run_step), (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file7g0mqir6.py:30\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function_trained.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     28\u001b[0m do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     29\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mpredict_step, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies(ag__\u001b[38;5;241m.\u001b[39mld(_minimum_control_deps)(ag__\u001b[38;5;241m.\u001b[39mld(outputs))):\n\u001b[1;32m     32\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39m_predict_counter\u001b[38;5;241m.\u001b[39massign_add, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filequn_jha3.py:32\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), fscope)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileveou_c_2.py:44\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mdebugging\u001b[38;5;241m.\u001b[39mis_traceback_filtering_enabled, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileveou_c_2.py:40\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     39\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_process_traceback_frames), (ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39m__traceback__,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39mwith_traceback, (ag__\u001b[38;5;241m.\u001b[39mld(filtered_tb),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileveou_c_2.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileimm4n2q8.py:67\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28msuper\u001b[39m), (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileveou_c_2.py:44\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mdebugging\u001b[38;5;241m.\u001b[39mis_traceback_filtering_enabled, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileveou_c_2.py:40\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     39\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_process_traceback_frames), (ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39m__traceback__,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39mwith_traceback, (ag__\u001b[38;5;241m.\u001b[39mld(filtered_tb),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileveou_c_2.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filetw3s25uj.py:242\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m namescope_stack \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamescope_stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_in_functional_construction_mode), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(inputs), ag__\u001b[38;5;241m.\u001b[39mld(args), ag__\u001b[38;5;241m.\u001b[39mld(kwargs), ag__\u001b[38;5;241m.\u001b[39mld(input_list)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), if_body_11, else_body_11, get_state_11, set_state_11, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_list\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filetw3s25uj.py:187\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.else_body_11\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_autocast, if_body_7, else_body_7, get_state_7, set_state_7, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(autocast_variable)\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m--> 187\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(call_fn), (ag__\u001b[38;5;241m.\u001b[39mld(inputs),) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_8\u001b[39m():\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filel9puqnkl.py:162\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     message \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    161\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(arguments_context), if_body_5, else_body_5, get_state_6, set_state_6, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_e\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments_context\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(new_e)\u001b[38;5;241m.\u001b[39mwith_traceback, (ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39m__traceback__,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     signature \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignature\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filel9puqnkl.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope_1)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file3lfsir1x.py:232\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    230\u001b[0m has_secondary_tasks \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhas_secondary_tasks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    231\u001b[0m item_idx \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_idx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 232\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_semantics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_8, else_body_8, get_state_11, set_state_11, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file3lfsir1x.py:43\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_8\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_8\u001b[39m():\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m retval_, do_return\n\u001b[0;32m---> 43\u001b[0m     normalized_inputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_build_normalized_inputs, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     44\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     45\u001b[0m     has_secondary_tasks \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28many\u001b[39m), ([ag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mld(t)\u001b[38;5;241m.\u001b[39mprimary) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_multitask],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filey80y390p.py:99\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___build_normalized_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     97\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28misinstance\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(inputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mdict\u001b[39m)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), if_body_4, else_body_4, get_state_4, set_state_4, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m semantic_inputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf_core)\u001b[38;5;241m.\u001b[39mcombine_tensors_and_semantics, (ag__\u001b[38;5;241m.\u001b[39mld(inputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_semantics), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 99\u001b[0m normalized_semantic_inputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf_core)\u001b[38;5;241m.\u001b[39mnormalize_inputs, (ag__\u001b[38;5;241m.\u001b[39mld(semantic_inputs),), \u001b[38;5;28mdict\u001b[39m(categorical_integer_offset_correction\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_advanced_arguments\u001b[38;5;241m.\u001b[39mdisable_categorical_integer_offset_correction)), fscope)\n\u001b[1;32m    100\u001b[0m normalized_inputs, _ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf_core)\u001b[38;5;241m.\u001b[39mdecombine_tensors_and_semantics, (ag__\u001b[38;5;241m.\u001b[39mld(normalized_semantic_inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py:205\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__normalize_inputs\u001b[0;34m(inputs, categorical_integer_offset_correction)\u001b[0m\n\u001b[1;32m    203\u001b[0m value \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    204\u001b[0m semantic_tensor \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic_tensor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(inputs)\u001b[38;5;241m.\u001b[39mitems, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state_13, set_state_13, (), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(key, semantic_tensor)\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py:201\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__normalize_inputs.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m    199\u001b[0m         ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39msemantic \u001b[38;5;241m==\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(Semantic)\u001b[38;5;241m.\u001b[39mCATEGORICAL_SET, if_body_10, else_body_10, get_state_10, set_state_10, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_inputs[key]\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    200\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39msemantic \u001b[38;5;241m==\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(Semantic)\u001b[38;5;241m.\u001b[39mCATEGORICAL, if_body_11, else_body_11, get_state_11, set_state_11, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_inputs[key]\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39msemantic \u001b[38;5;129;01min\u001b[39;00m [ag__\u001b[38;5;241m.\u001b[39mld(Semantic)\u001b[38;5;241m.\u001b[39mNUMERICAL, ag__\u001b[38;5;241m.\u001b[39mld(Semantic)\u001b[38;5;241m.\u001b[39mDISCRETIZED_NUMERICAL], if_body_12, else_body_12, get_state_12, set_state_12, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_inputs[key]\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py:60\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__normalize_inputs.<locals>.loop_body.<locals>.if_body_12\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;167;01mValueError\u001b[39;00m), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon supported tensor dtype \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for semantic \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of feature \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat, (ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype, ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39msemantic, ag__\u001b[38;5;241m.\u001b[39mld(key)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 60\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(FlexibleNumericalTypes), if_body, else_body, get_state, set_state, (), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py:59\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__normalize_inputs.<locals>.loop_body.<locals>.if_body_12.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;167;01mValueError\u001b[39;00m), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon supported tensor dtype \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for semantic \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of feature \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat, (ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdtype, ag__\u001b[38;5;241m.\u001b[39mld(semantic_tensor)\u001b[38;5;241m.\u001b[39msemantic, ag__\u001b[38;5;241m.\u001b[39mld(key)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py\", line 486, in run_step  *\n        outputs = model.predict_step(data)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 2377, in predict_step  *\n        return self(x, training=False)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 565, in error_handler  *\n        del filtered_tb\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 588, in __call__  *\n        return super().__call__(*args, **kwargs)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/training.py\", line 560, in error_handler  *\n        filtered_tb = _process_traceback_frames(e.__traceback__)\n    File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filel9puqnkl.py\", line 162, in error_handler  **\n        raise ag__.converted_call(ag__.ld(new_e).with_traceback, (ag__.ld(e).__traceback__,), None, fscope_1) from None\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filel9puqnkl.py\", line 34, in error_handler\n        retval__1 = ag__.converted_call(ag__.ld(fn), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file3lfsir1x.py\", line 232, in tf__call\n        ag__.if_stmt(ag__.ld(self)._semantics is None, if_body_8, else_body_8, get_state_11, set_state_11, ('do_return', 'retval_'), 2)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_file3lfsir1x.py\", line 43, in else_body_8\n        normalized_inputs = ag__.converted_call(ag__.ld(self)._build_normalized_inputs, (ag__.ld(inputs),), None, fscope)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_filey80y390p.py\", line 99, in tf___build_normalized_inputs\n        normalized_semantic_inputs = ag__.converted_call(ag__.ld(tf_core).normalize_inputs, (ag__.ld(semantic_inputs),), dict(categorical_integer_offset_correction=ag__.not_(ag__.ld(self)._advanced_arguments.disable_categorical_integer_offset_correction)), fscope)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 205, in tf__normalize_inputs\n        ag__.for_stmt(ag__.converted_call(ag__.ld(inputs).items, (), None, fscope), None, loop_body, get_state_13, set_state_13, (), {'iterate_names': '(key, semantic_tensor)'})\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 201, in loop_body\n        ag__.if_stmt(ag__.ld(semantic_tensor).semantic in [ag__.ld(Semantic).NUMERICAL, ag__.ld(Semantic).DISCRETIZED_NUMERICAL], if_body_12, else_body_12, get_state_12, set_state_12, ('normalized_inputs[key]',), 1)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 60, in if_body_12\n        ag__.if_stmt(ag__.ld(semantic_tensor).tensor.dtype in ag__.ld(FlexibleNumericalTypes), if_body, else_body, get_state, set_state, (), 0)\n    File \"/var/folders/lj/1fkt9p5950q_xh36l9svgyyw0000gn/T/__autograph_generated_fileml0jtodi.py\", line 59, in else_body\n        raise ag__.converted_call(ag__.ld(ValueError), (ag__.converted_call('Non supported tensor dtype {} for semantic {} of feature {}'.format, (ag__.ld(semantic_tensor).tensor.dtype, ag__.ld(semantic_tensor).semantic, ag__.ld(key)), None, fscope),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'gradient_boosted_trees_model_1' (type GradientBoostedTreesModel).\n    \n    in user code:\n    \n        File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py\", line 672, in call  *\n            normalized_inputs = self._build_normalized_inputs(inputs)\n        File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/keras/core_inference.py\", line 634, in _build_normalized_inputs  *\n            normalized_semantic_inputs = tf_core.normalize_inputs(\n        File \"/Users/admin/anaconda3/lib/python3.11/site-packages/tensorflow_decision_forests/tensorflow/core_inference.py\", line 220, in normalize_inputs  *\n            raise ValueError(\n    \n        ValueError: Non supported tensor dtype <dtype: 'string'> for semantic Semantic.NUMERICAL of feature LotFrontage\n    \n    \n    Call arguments received by layer 'gradient_boosted_trees_model_1' (type GradientBoostedTreesModel):\n      • inputs={'Id': 'tf.Tensor(shape=(None,), dtype=int64)', 'MSSubClass': 'tf.Tensor(shape=(None,), dtype=int64)', 'MSZoning': 'tf.Tensor(shape=(None,), dtype=string)', 'LotFrontage': 'tf.Tensor(shape=(None,), dtype=string)', 'LotArea': 'tf.Tensor(shape=(None,), dtype=int64)', 'Street': 'tf.Tensor(shape=(None,), dtype=string)', 'Alley': 'tf.Tensor(shape=(None,), dtype=string)', 'LotShape': 'tf.Tensor(shape=(None,), dtype=string)', 'LandContour': 'tf.Tensor(shape=(None,), dtype=string)', 'Utilities': 'tf.Tensor(shape=(None,), dtype=string)', 'LotConfig': 'tf.Tensor(shape=(None,), dtype=string)', 'LandSlope': 'tf.Tensor(shape=(None,), dtype=string)', 'Neighborhood': 'tf.Tensor(shape=(None,), dtype=string)', 'Condition1': 'tf.Tensor(shape=(None,), dtype=string)', 'Condition2': 'tf.Tensor(shape=(None,), dtype=string)', 'BldgType': 'tf.Tensor(shape=(None,), dtype=string)', 'HouseStyle': 'tf.Tensor(shape=(None,), dtype=string)', 'OverallQual': 'tf.Tensor(shape=(None,), dtype=int64)', 'OverallCond': 'tf.Tensor(shape=(None,), dtype=int64)', 'YearBuilt': 'tf.Tensor(shape=(None,), dtype=int64)', 'YearRemodAdd': 'tf.Tensor(shape=(None,), dtype=int64)', 'RoofStyle': 'tf.Tensor(shape=(None,), dtype=string)', 'RoofMatl': 'tf.Tensor(shape=(None,), dtype=string)', 'Exterior1st': 'tf.Tensor(shape=(None,), dtype=string)', 'Exterior2nd': 'tf.Tensor(shape=(None,), dtype=string)', 'MasVnrType': 'tf.Tensor(shape=(None,), dtype=string)', 'MasVnrArea': 'tf.Tensor(shape=(None,), dtype=string)', 'ExterQual': 'tf.Tensor(shape=(None,), dtype=string)', 'ExterCond': 'tf.Tensor(shape=(None,), dtype=string)', 'Foundation': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtQual': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtCond': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtExposure': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinType1': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinSF1': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinType2': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtFinSF2': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtUnfSF': 'tf.Tensor(shape=(None,), dtype=string)', 'TotalBsmtSF': 'tf.Tensor(shape=(None,), dtype=string)', 'Heating': 'tf.Tensor(shape=(None,), dtype=string)', 'HeatingQC': 'tf.Tensor(shape=(None,), dtype=string)', 'CentralAir': 'tf.Tensor(shape=(None,), dtype=string)', 'Electrical': 'tf.Tensor(shape=(None,), dtype=string)', '1stFlrSF': 'tf.Tensor(shape=(None,), dtype=int64)', '2ndFlrSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'LowQualFinSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'GrLivArea': 'tf.Tensor(shape=(None,), dtype=int64)', 'BsmtFullBath': 'tf.Tensor(shape=(None,), dtype=string)', 'BsmtHalfBath': 'tf.Tensor(shape=(None,), dtype=string)', 'FullBath': 'tf.Tensor(shape=(None,), dtype=int64)', 'HalfBath': 'tf.Tensor(shape=(None,), dtype=int64)', 'BedroomAbvGr': 'tf.Tensor(shape=(None,), dtype=int64)', 'KitchenAbvGr': 'tf.Tensor(shape=(None,), dtype=int64)', 'KitchenQual': 'tf.Tensor(shape=(None,), dtype=string)', 'TotRmsAbvGrd': 'tf.Tensor(shape=(None,), dtype=int64)', 'Functional': 'tf.Tensor(shape=(None,), dtype=string)', 'Fireplaces': 'tf.Tensor(shape=(None,), dtype=int64)', 'FireplaceQu': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageType': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageYrBlt': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageFinish': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageCars': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageArea': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageQual': 'tf.Tensor(shape=(None,), dtype=string)', 'GarageCond': 'tf.Tensor(shape=(None,), dtype=string)', 'PavedDrive': 'tf.Tensor(shape=(None,), dtype=string)', 'WoodDeckSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'OpenPorchSF': 'tf.Tensor(shape=(None,), dtype=int64)', 'EnclosedPorch': 'tf.Tensor(shape=(None,), dtype=int64)', '3SsnPorch': 'tf.Tensor(shape=(None,), dtype=int64)', 'ScreenPorch': 'tf.Tensor(shape=(None,), dtype=int64)', 'PoolArea': 'tf.Tensor(shape=(None,), dtype=int64)', 'PoolQC': 'tf.Tensor(shape=(None,), dtype=string)', 'Fence': 'tf.Tensor(shape=(None,), dtype=string)', 'MiscFeature': 'tf.Tensor(shape=(None,), dtype=string)', 'MiscVal': 'tf.Tensor(shape=(None,), dtype=int64)', 'MoSold': 'tf.Tensor(shape=(None,), dtype=int64)', 'YrSold': 'tf.Tensor(shape=(None,), dtype=int64)', 'SaleType': 'tf.Tensor(shape=(None,), dtype=string)', 'SaleCondition': 'tf.Tensor(shape=(None,), dtype=string)'}\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test dataset\n",
    "predictions_gb_log = model_gb_regressor.predict(testing)\n",
    "\n",
    "# Reverse log transformation for predictions\n",
    "predictions_gb = np.exp(predictions_gb_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a443b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
