{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613f06a2-a6a0-4d42-b1bb-1bc8c30fa45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">ðŸŒ² Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f35dbd-1ce3-4f5d-be1b-90d2f41fc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/processed/train_data.csv')\n",
    "test = pd.read_csv('../data/processed/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a0a648-54c4-4f1b-8481-1c716b6896c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split input and output\n",
    "X_train=train.drop(['SalePrice'], axis=1)\n",
    "y_train= train['SalePrice']\n",
    "\n",
    "X_test=test.drop(['SalePrice'], axis=1)\n",
    "y_test= test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c1056-ff4e-4332-bdec-34575a6ee19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding - convert categorical columns to numerical for linear regression. \n",
    "#there was an error with vanishing columns in test. This fixes it. \n",
    "X_train_one_hot = pd.get_dummies(X_train, drop_first=True) \n",
    "cols = X_train_one_hot.columns.tolist()\n",
    "X_test_one_hot = pd.get_dummies(X_test, drop_first=True) \n",
    "X_test_one_hot = X_test_one_hot.reindex(columns=cols).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc16b2-b4d5-4462-ae53-7d132417cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression: \n",
    "#fit_intercept=False is needed as collinearity of one hot encoding, first row has to be dropped. \n",
    "reg = linear_model.LinearRegression(fit_intercept=False)\n",
    "reg.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a11675-5ff1-49a2-8a0c-4c77baea66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict sales price on test set\n",
    "predictions_lm = reg.predict(X_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa535a-48bf-45e7-891f-603ed00e0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply inverse transformation to bring predictions back to the original scale\n",
    "predictions_lm = np.exp(predictions_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE \n",
    "rms = mean_squared_error(np.exp(y_test), predictions_lm, squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066aef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow decision trees\n",
    "#!pip install tensorflow_decision_forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0a3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe into a TensorFlow dataset\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"SalePrice\", task = tfdf.keras.Task.REGRESSION)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=\"SalePrice\", task = tfdf.keras.Task.REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96763e-d63d-4074-8646-b12861b7b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomSearch tuner\n",
    "tuner_rf = tfdf.tuner.RandomSearch(num_trials=20)\n",
    "\n",
    "tuner_rf.choice(\"num_trees\", [100, 200, 500])\n",
    "tuner_rf.choice(\"max_depth\", [-1, 10, 30])\n",
    "tuner_rf.choice(\"min_examples\", [2, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION, tuner=tuner_rf)\n",
    "model.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059223b4-113a-43ca-b423-8db7aa7ef195",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_logs_rf = model.make_inspector().tuning_logs()\n",
    "# Best hyper-parameters.\n",
    "tuning_logs_rf[tuning_logs_rf.best].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(metrics=[\"accuracy\"])\n",
    "print(model.evaluate(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = model.make_inspector()\n",
    "inspector.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6909f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note this RMSE is on the logarmithic data, not the actual data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the actual RMSE\n",
    "preds = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predics=np.exp(preds)\n",
    "y=test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dae43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(np.exp(y), preds, squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#next acitivity, explore all of these methods and compare RMSE of all\n",
    "\n",
    "tfdf.keras.get_all_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a60581-41ab-453a-9439-97721c7a9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostedTreesModel - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81fa9e-3645-4ba3-a804-66fe0fc788d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomSearch tuner\n",
    "tuner_gb = tfdf.tuner.RandomSearch(num_trials=10)\n",
    "\n",
    "tuner_gb.choice(\"num_trees\", [50, 100, 200, 500, 1000])\n",
    "tuner_gb.choice(\"shrinkage\", [0.01, 0.05, 0.1, 0.3, 0.5])\n",
    "tuner_gb.choice(\"max_depth\", [3, 4, 5, 6, 8, 10])\n",
    "tuner_gb.choice(\"min_examples\", [2, 5, 10, 15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4664ee2-e903-430a-90b6-01021c916065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Gradient Boosted Trees Regression model\n",
    "model_gb_regressor = tfdf.keras.GradientBoostedTreesModel(\n",
    "    task=tfdf.keras.Task.REGRESSION,\n",
    "    tuner=tuner_gb\n",
    ")\n",
    "\n",
    "model_gb_regressor.fit(train_ds)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e943537-2ae9-414b-9629-005510e635cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_logs_gb = model_gb_regressor.make_inspector().tuning_logs()\n",
    "# Best hyper-parameters.\n",
    "tuning_logs_gb[tuning_logs.best].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a411a2-4a98-4c61-b93d-f30a8550183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test dataset\n",
    "predictions_gb_log = model_gb_regressor.predict(test_ds)\n",
    "\n",
    "# Reverse log transformation for predictions\n",
    "y_pred_gb = np.exp(predictions_gb_log)\n",
    "\n",
    "# Reverse the log transformation for true variable\n",
    "y_true_gb = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab04474-f9d1-4b53-bd18-16e8d3d47356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE and evaluate model performance\n",
    "rmse_gb = np.sqrt(mean_squared_error(y_true_gb, y_pred_gb))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_gb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cart model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a80b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "model_cm_regression = tfdf.keras.CartModel(task=tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "model_cm_regression.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the same dataset (or test set)\n",
    "predictions_log_cm = model_cm_regression.predict(train_ds)\n",
    "\n",
    "# Reverse the log transformation (use np.exp to get the original scale)\n",
    "predictions_original_scale_cm = np.exp(predictions_log_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eaba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = mean_squared_error(y_true, predictions_original_scale_cm, squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b307ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0, oob_score=True)\n",
    "regressor.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc60aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = regressor.predict(X_test_one_hot)\n",
    "mse = mean_squared_error(np.exp(y_test), np.exp(predictions))\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0513b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig,ax = plt.subplots(figsize=(6,6))\n",
    "    ax.set_title('House price predictions',fontsize=20)\n",
    "    ax.set_ylabel('predicted',fontsize=12)\n",
    "    ax.set_xlabel('actual',fontsize=12)\n",
    "    ax.scatter(np.exp(y_test), np.exp(predictions_rf),label='Random Forest')\n",
    "    ax.scatter(y_true, predictions_original_scale_cm,label='Cart model')\n",
    "    ax.scatter(y_true, predictions_original_scale,label='GradientBoostedTreesModel')\n",
    "    ax.scatter(np.exp(y_test), predictions_lm,label='Linear model')\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e63783d-22fa-4fe6-b805-8704f2e897f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map model names to their corresponding classes\n",
    "models = {\n",
    "    \"gradient_boosted_trees\": tfdf.keras.GradientBoostedTreesModel,\n",
    "    \"random_forest\": tfdf.keras.RandomForestModel\n",
    "}\n",
    "\n",
    "# Define model hyperparameter configurations\n",
    "params = {\n",
    "    \"gradient_boosted_trees\": {\n",
    "        \"num_trees\": [50, 100, 200, 500, 1000],\n",
    "        \"shrinkage\": [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "        \"max_depth\": [4, 6, 8, 10],\n",
    "        \"min_examples\": [2, 5, 10, 15]\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"num_trees\": [100, 200, 500],\n",
    "        \"max_depth\": [-1, 10, 30],\n",
    "        \"min_examples\": [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "num_trials = {\n",
    "    \"gradient_boosted_trees\": 10,\n",
    "    \"random_forest\": 20\n",
    "}\n",
    "\n",
    "# Placeholder to store model output\n",
    "output_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e1f0d83-257c-4d59-99ab-0abf3b4f8a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmplu8yr3q4 as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 21:27:37.533819: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-01-06 21:27:37.533850: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-01-06 21:27:37.533855: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.323039. Found 1165 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736216857.863395 35735652 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1736216857.863412 35735652 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1736216857.863418 35735652 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: NUMERICAL\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1736216857.863561 35735652 kernel.cc:401] Number of batches: 2\n",
      "I0000 00:00:1736216857.863565 35735652 kernel.cc:402] Number of examples: 1165\n",
      "I0000 00:00:1736216857.864672 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column BsmtCond (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864684 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Condition1 (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864688 35735652 data_spec_inference.cc:354] 6 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Condition2 (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864691 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Electrical (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864694 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column ExterCond (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864697 35735652 data_spec_inference.cc:354] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Exterior1st (10 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864701 35735652 data_spec_inference.cc:354] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Exterior2nd (12 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864707 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Foundation (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864710 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Functional (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864712 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column GarageCond (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864716 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column GarageQual (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864718 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column GarageType (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864721 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Heating (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864723 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column HeatingQC (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864731 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column LotConfig (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864737 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column MiscFeature (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864741 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Neighborhood (24 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864747 35735652 data_spec_inference.cc:354] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column PoolQC (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864749 35735652 data_spec_inference.cc:354] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column RoofMatl (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864752 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column RoofStyle (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864755 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column SaleCondition (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864758 35735652 data_spec_inference.cc:354] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column SaleType (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864761 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Street (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.864763 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Utilities (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216857.865602 35735652 kernel.cc:802] Training dataset:\n",
      "Number of records: 1165\n",
      "Number of columns: 81\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 43 (53.0864%)\n",
      "\tNUMERICAL: 38 (46.9136%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 43 (53.0864%)\n",
      "\t3: \"Alley\" CATEGORICAL num-nas:1096 (94.0773%) has-dict vocab-size:3 zero-ood-items most-frequent:\"Grvl\" 37 (53.6232%)\n",
      "\t5: \"BldgType\" CATEGORICAL has-dict vocab-size:6 zero-ood-items most-frequent:\"1Fam\" 976 (83.7768%)\n",
      "\t6: \"BsmtCond\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:4 num-oods:2 (0.175285%) most-frequent:\"TA\" 1052 (92.1998%)\n",
      "\t7: \"BsmtExposure\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:5 zero-ood-items most-frequent:\"No\" 759 (66.5206%)\n",
      "\t10: \"BsmtFinType1\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:7 zero-ood-items most-frequent:\"Unf\" 346 (30.3243%)\n",
      "\t11: \"BsmtFinType2\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:7 zero-ood-items most-frequent:\"Unf\" 1005 (88.0806%)\n",
      "\t14: \"BsmtQual\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:5 zero-ood-items most-frequent:\"TA\" 518 (45.3988%)\n",
      "\t16: \"CentralAir\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"Y\" 1097 (94.1631%)\n",
      "\t17: \"Condition1\" CATEGORICAL has-dict vocab-size:8 num-oods:4 (0.343348%) most-frequent:\"Norm\" 1010 (86.6953%)\n",
      "\t18: \"Condition2\" CATEGORICAL has-dict vocab-size:2 num-oods:11 (0.944206%) most-frequent:\"Norm\" 1154 (99.0558%)\n",
      "\t19: \"Electrical\" CATEGORICAL has-dict vocab-size:4 num-oods:2 (0.171674%) most-frequent:\"SBrkr\" 1071 (91.9313%)\n",
      "\t21: \"ExterCond\" CATEGORICAL has-dict vocab-size:4 num-oods:4 (0.343348%) most-frequent:\"TA\" 1022 (87.7253%)\n",
      "\t22: \"ExterQual\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"TA\" 712 (61.1159%)\n",
      "\t23: \"Exterior1st\" CATEGORICAL has-dict vocab-size:11 num-oods:3 (0.257511%) most-frequent:\"VinylSd\" 421 (36.1373%)\n",
      "\t24: \"Exterior2nd\" CATEGORICAL has-dict vocab-size:13 num-oods:7 (0.600858%) most-frequent:\"VinylSd\" 412 (35.3648%)\n",
      "\t25: \"Fence\" CATEGORICAL num-nas:945 (81.1159%) has-dict vocab-size:5 zero-ood-items most-frequent:\"MnPrv\" 123 (55.9091%)\n",
      "\t26: \"FireplaceQu\" CATEGORICAL num-nas:544 (46.6953%) has-dict vocab-size:6 zero-ood-items most-frequent:\"Gd\" 312 (50.2415%)\n",
      "\t28: \"Foundation\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.600858%) most-frequent:\"PConc\" 524 (44.9785%)\n",
      "\t30: \"Functional\" CATEGORICAL has-dict vocab-size:7 num-oods:1 (0.0858369%) most-frequent:\"Typ\" 1084 (93.0472%)\n",
      "\t33: \"GarageCond\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:5 num-oods:1 (0.0914913%) most-frequent:\"TA\" 1050 (96.0659%)\n",
      "\t34: \"GarageFinish\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:4 zero-ood-items most-frequent:\"Unf\" 460 (42.086%)\n",
      "\t35: \"GarageQual\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:4 num-oods:5 (0.457457%) most-frequent:\"TA\" 1040 (95.151%)\n",
      "\t36: \"GarageType\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:6 num-oods:3 (0.274474%) most-frequent:\"Attchd\" 696 (63.678%)\n",
      "\t40: \"Heating\" CATEGORICAL has-dict vocab-size:4 num-oods:5 (0.429185%) most-frequent:\"GasA\" 1139 (97.7682%)\n",
      "\t41: \"HeatingQC\" CATEGORICAL has-dict vocab-size:5 num-oods:1 (0.0858369%) most-frequent:\"Ex\" 596 (51.1588%)\n",
      "\t42: \"HouseStyle\" CATEGORICAL has-dict vocab-size:9 zero-ood-items most-frequent:\"1Story\" 575 (49.3562%)\n",
      "\t45: \"KitchenQual\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"TA\" 581 (49.8712%)\n",
      "\t46: \"LandContour\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"Lvl\" 1042 (89.4421%)\n",
      "\t47: \"LandSlope\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Gtl\" 1102 (94.5923%)\n",
      "\t49: \"LotConfig\" CATEGORICAL has-dict vocab-size:5 num-oods:4 (0.343348%) most-frequent:\"Inside\" 836 (71.7597%)\n",
      "\t51: \"LotShape\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"Reg\" 734 (63.0043%)\n",
      "\t54: \"MSZoning\" CATEGORICAL has-dict vocab-size:6 zero-ood-items most-frequent:\"RL\" 920 (78.97%)\n",
      "\t56: \"MasVnrType\" CATEGORICAL num-nas:689 (59.1416%) has-dict vocab-size:4 zero-ood-items most-frequent:\"BrkFace\" 356 (74.7899%)\n",
      "\t57: \"MiscFeature\" CATEGORICAL num-nas:1122 (96.309%) has-dict vocab-size:2 num-oods:4 (9.30233%) most-frequent:\"Shed\" 39 (90.6977%)\n",
      "\t60: \"Neighborhood\" CATEGORICAL has-dict vocab-size:25 num-oods:2 (0.171674%) most-frequent:\"NAmes\" 183 (15.7082%)\n",
      "\t64: \"PavedDrive\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Y\" 1071 (91.9313%)\n",
      "\t66: \"PoolQC\" CATEGORICAL num-nas:1161 (99.6567%) has-dict vocab-size:1 num-oods:4 (100%)\n",
      "\t67: \"RoofMatl\" CATEGORICAL has-dict vocab-size:4 num-oods:5 (0.429185%) most-frequent:\"CompShg\" 1146 (98.3691%)\n",
      "\t68: \"RoofStyle\" CATEGORICAL has-dict vocab-size:6 num-oods:2 (0.171674%) most-frequent:\"Gable\" 903 (77.5107%)\n",
      "\t69: \"SaleCondition\" CATEGORICAL has-dict vocab-size:6 num-oods:2 (0.171674%) most-frequent:\"Normal\" 951 (81.6309%)\n",
      "\t70: \"SaleType\" CATEGORICAL has-dict vocab-size:6 num-oods:11 (0.944206%) most-frequent:\"WD\" 1004 (86.1803%)\n",
      "\t72: \"Street\" CATEGORICAL has-dict vocab-size:2 num-oods:4 (0.343348%) most-frequent:\"Pave\" 1161 (99.6567%)\n",
      "\t75: \"Utilities\" CATEGORICAL has-dict vocab-size:2 num-oods:1 (0.0858369%) most-frequent:\"AllPub\" 1164 (99.9142%)\n",
      "\n",
      "NUMERICAL: 38 (46.9136%)\n",
      "\t0: \"1stFlrSF\" NUMERICAL mean:1163.62 min:372 max:4692 sd:390.377\n",
      "\t1: \"2ndFlrSF\" NUMERICAL mean:354.442 min:0 max:1872 sd:442.352\n",
      "\t2: \"3SsnPorch\" NUMERICAL mean:3.25322 min:0 max:508 sd:28.2724\n",
      "\t4: \"BedroomAbvGr\" NUMERICAL mean:2.8824 min:0 max:8 sd:0.819761\n",
      "\t8: \"BsmtFinSF1\" NUMERICAL mean:448.565 min:0 max:5644 sd:460.659\n",
      "\t9: \"BsmtFinSF2\" NUMERICAL mean:46.9202 min:0 max:1127 sd:160.976\n",
      "\t12: \"BsmtFullBath\" NUMERICAL mean:0.427468 min:0 max:3 sd:0.518434\n",
      "\t13: \"BsmtHalfBath\" NUMERICAL mean:0.0609442 min:0 max:2 sd:0.2463\n",
      "\t15: \"BsmtUnfSF\" NUMERICAL mean:565.572 min:0 max:2336 sd:435.502\n",
      "\t20: \"EnclosedPorch\" NUMERICAL mean:22.1382 min:0 max:552 sd:61.1196\n",
      "\t27: \"Fireplaces\" NUMERICAL mean:0.616309 min:0 max:3 sd:0.638863\n",
      "\t29: \"FullBath\" NUMERICAL mean:1.57425 min:0 max:3 sd:0.554983\n",
      "\t31: \"GarageArea\" NUMERICAL mean:471.641 min:0 max:1418 sd:218.173\n",
      "\t32: \"GarageCars\" NUMERICAL mean:1.76223 min:0 max:4 sd:0.759002\n",
      "\t37: \"GarageYrBlt\" NUMERICAL num-nas:72 (6.18026%) mean:1978.74 min:1900 max:2010 sd:24.8408\n",
      "\t38: \"GrLivArea\" NUMERICAL mean:1524.08 min:438 max:5642 sd:530.529\n",
      "\t39: \"HalfBath\" NUMERICAL mean:0.387124 min:0 max:2 sd:0.502702\n",
      "\t43: \"Id\" NUMERICAL mean:742.477 min:1 max:1460 sd:419.979\n",
      "\t44: \"KitchenAbvGr\" NUMERICAL mean:1.04464 min:0 max:3 sd:0.218616\n",
      "\t48: \"LotArea\" NUMERICAL mean:10582.5 min:1300 max:215245 sd:10340.4\n",
      "\t50: \"LotFrontage\" NUMERICAL mean:69.8532 min:21 max:313 sd:22.4105\n",
      "\t52: \"LowQualFinSF\" NUMERICAL mean:6.0206 min:0 max:572 sd:49.4899\n",
      "\t53: \"MSSubClass\" NUMERICAL mean:57.1202 min:20 max:190 sd:42.3212\n",
      "\t55: \"MasVnrArea\" NUMERICAL num-nas:6 (0.515021%) mean:107.459 min:0 max:1600 sd:185.966\n",
      "\t58: \"MiscVal\" NUMERICAL mean:44.3468 min:0 max:15500 sd:540.007\n",
      "\t59: \"MoSold\" NUMERICAL mean:6.36052 min:1 max:12 sd:2.66637\n",
      "\t61: \"OpenPorchSF\" NUMERICAL mean:47.206 min:0 max:547 sd:66.9365\n",
      "\t62: \"OverallCond\" NUMERICAL mean:5.58627 min:1 max:9 sd:1.12123\n",
      "\t63: \"OverallQual\" NUMERICAL mean:6.13047 min:1 max:10 sd:1.39409\n",
      "\t65: \"PoolArea\" NUMERICAL mean:1.90215 min:0 max:648 sd:32.6249\n",
      "\t71: \"ScreenPorch\" NUMERICAL mean:14.9167 min:0 max:480 sd:55.1891\n",
      "\t73: \"TotRmsAbvGrd\" NUMERICAL mean:6.56052 min:3 max:14 sd:1.64929\n",
      "\t74: \"TotalBsmtSF\" NUMERICAL mean:1061.06 min:0 max:6110 sd:433.612\n",
      "\t76: \"WoodDeckSF\" NUMERICAL mean:94.7476 min:0 max:857 sd:123.707\n",
      "\t77: \"YearBuilt\" NUMERICAL mean:1971.39 min:1872 max:2010 sd:30.5351\n",
      "\t78: \"YearRemodAdd\" NUMERICAL mean:1985.28 min:1950 max:2010 sd:20.5411\n",
      "\t79: \"YrSold\" NUMERICAL mean:2007.82 min:2006 max:2010 sd:1.33018\n",
      "\t80: \"__LABEL\" NUMERICAL mean:12.0314 min:10.4602 max:13.5345 sd:0.398999\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1736216857.865652 35735652 kernel.cc:818] Configure learner\n",
      "2025-01-06 21:27:37.865817: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-01-06 21:27:37.865828: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1850] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "2025-01-06 21:27:37.865831: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1864] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1736216857.865867 35735652 kernel.cc:831] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^1stFlrSF$\"\n",
      "features: \"^2ndFlrSF$\"\n",
      "features: \"^3SsnPorch$\"\n",
      "features: \"^Alley$\"\n",
      "features: \"^BedroomAbvGr$\"\n",
      "features: \"^BldgType$\"\n",
      "features: \"^BsmtCond$\"\n",
      "features: \"^BsmtExposure$\"\n",
      "features: \"^BsmtFinSF1$\"\n",
      "features: \"^BsmtFinSF2$\"\n",
      "features: \"^BsmtFinType1$\"\n",
      "features: \"^BsmtFinType2$\"\n",
      "features: \"^BsmtFullBath$\"\n",
      "features: \"^BsmtHalfBath$\"\n",
      "features: \"^BsmtQual$\"\n",
      "features: \"^BsmtUnfSF$\"\n",
      "features: \"^CentralAir$\"\n",
      "features: \"^Condition1$\"\n",
      "features: \"^Condition2$\"\n",
      "features: \"^Electrical$\"\n",
      "features: \"^EnclosedPorch$\"\n",
      "features: \"^ExterCond$\"\n",
      "features: \"^ExterQual$\"\n",
      "features: \"^Exterior1st$\"\n",
      "features: \"^Exterior2nd$\"\n",
      "features: \"^Fence$\"\n",
      "features: \"^FireplaceQu$\"\n",
      "features: \"^Fireplaces$\"\n",
      "features: \"^Foundation$\"\n",
      "features: \"^FullBath$\"\n",
      "features: \"^Functional$\"\n",
      "features: \"^GarageArea$\"\n",
      "features: \"^GarageCars$\"\n",
      "features: \"^GarageCond$\"\n",
      "features: \"^GarageFinish$\"\n",
      "features: \"^GarageQual$\"\n",
      "features: \"^GarageType$\"\n",
      "features: \"^GarageYrBlt$\"\n",
      "features: \"^GrLivArea$\"\n",
      "features: \"^HalfBath$\"\n",
      "features: \"^Heating$\"\n",
      "features: \"^HeatingQC$\"\n",
      "features: \"^HouseStyle$\"\n",
      "features: \"^Id$\"\n",
      "features: \"^KitchenAbvGr$\"\n",
      "features: \"^KitchenQual$\"\n",
      "features: \"^LandContour$\"\n",
      "features: \"^LandSlope$\"\n",
      "features: \"^LotArea$\"\n",
      "features: \"^LotConfig$\"\n",
      "features: \"^LotFrontage$\"\n",
      "features: \"^LotShape$\"\n",
      "features: \"^LowQualFinSF$\"\n",
      "features: \"^MSSubClass$\"\n",
      "features: \"^MSZoning$\"\n",
      "features: \"^MasVnrArea$\"\n",
      "features: \"^MasVnrType$\"\n",
      "features: \"^MiscFeature$\"\n",
      "features: \"^MiscVal$\"\n",
      "features: \"^MoSold$\"\n",
      "features: \"^Neighborhood$\"\n",
      "features: \"^OpenPorchSF$\"\n",
      "features: \"^OverallCond$\"\n",
      "features: \"^OverallQual$\"\n",
      "features: \"^PavedDrive$\"\n",
      "features: \"^PoolArea$\"\n",
      "features: \"^PoolQC$\"\n",
      "features: \"^RoofMatl$\"\n",
      "features: \"^RoofStyle$\"\n",
      "features: \"^SaleCondition$\"\n",
      "features: \"^SaleType$\"\n",
      "features: \"^ScreenPorch$\"\n",
      "features: \"^Street$\"\n",
      "features: \"^TotRmsAbvGrd$\"\n",
      "features: \"^TotalBsmtSF$\"\n",
      "features: \"^Utilities$\"\n",
      "features: \"^WoodDeckSF$\"\n",
      "features: \"^YearBuilt$\"\n",
      "features: \"^YearRemodAdd$\"\n",
      "features: \"^YrSold$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: REGRESSION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "    features: \"^1stFlrSF$\"\n",
      "    features: \"^2ndFlrSF$\"\n",
      "    features: \"^3SsnPorch$\"\n",
      "    features: \"^Alley$\"\n",
      "    features: \"^BedroomAbvGr$\"\n",
      "    features: \"^BldgType$\"\n",
      "    features: \"^BsmtCond$\"\n",
      "    features: \"^BsmtExposure$\"\n",
      "    features: \"^BsmtFinSF1$\"\n",
      "    features: \"^BsmtFinSF2$\"\n",
      "    features: \"^BsmtFinType1$\"\n",
      "    features: \"^BsmtFinType2$\"\n",
      "    features: \"^BsmtFullBath$\"\n",
      "    features: \"^BsmtHalfBath$\"\n",
      "    features: \"^BsmtQual$\"\n",
      "    features: \"^BsmtUnfSF$\"\n",
      "    features: \"^CentralAir$\"\n",
      "    features: \"^Condition1$\"\n",
      "    features: \"^Condition2$\"\n",
      "    features: \"^Electrical$\"\n",
      "    features: \"^EnclosedPorch$\"\n",
      "    features: \"^ExterCond$\"\n",
      "    features: \"^ExterQual$\"\n",
      "    features: \"^Exterior1st$\"\n",
      "    features: \"^Exterior2nd$\"\n",
      "    features: \"^Fence$\"\n",
      "    features: \"^FireplaceQu$\"\n",
      "    features: \"^Fireplaces$\"\n",
      "    features: \"^Foundation$\"\n",
      "    features: \"^FullBath$\"\n",
      "    features: \"^Functional$\"\n",
      "    features: \"^GarageArea$\"\n",
      "    features: \"^GarageCars$\"\n",
      "    features: \"^GarageCond$\"\n",
      "    features: \"^GarageFinish$\"\n",
      "    features: \"^GarageQual$\"\n",
      "    features: \"^GarageType$\"\n",
      "    features: \"^GarageYrBlt$\"\n",
      "    features: \"^GrLivArea$\"\n",
      "    features: \"^HalfBath$\"\n",
      "    features: \"^Heating$\"\n",
      "    features: \"^HeatingQC$\"\n",
      "    features: \"^HouseStyle$\"\n",
      "    features: \"^Id$\"\n",
      "    features: \"^KitchenAbvGr$\"\n",
      "    features: \"^KitchenQual$\"\n",
      "    features: \"^LandContour$\"\n",
      "    features: \"^LandSlope$\"\n",
      "    features: \"^LotArea$\"\n",
      "    features: \"^LotConfig$\"\n",
      "    features: \"^LotFrontage$\"\n",
      "    features: \"^LotShape$\"\n",
      "    features: \"^LowQualFinSF$\"\n",
      "    features: \"^MSSubClass$\"\n",
      "    features: \"^MSZoning$\"\n",
      "    features: \"^MasVnrArea$\"\n",
      "    features: \"^MasVnrType$\"\n",
      "    features: \"^MiscFeature$\"\n",
      "    features: \"^MiscVal$\"\n",
      "    features: \"^MoSold$\"\n",
      "    features: \"^Neighborhood$\"\n",
      "    features: \"^OpenPorchSF$\"\n",
      "    features: \"^OverallCond$\"\n",
      "    features: \"^OverallQual$\"\n",
      "    features: \"^PavedDrive$\"\n",
      "    features: \"^PoolArea$\"\n",
      "    features: \"^PoolQC$\"\n",
      "    features: \"^RoofMatl$\"\n",
      "    features: \"^RoofStyle$\"\n",
      "    features: \"^SaleCondition$\"\n",
      "    features: \"^SaleType$\"\n",
      "    features: \"^ScreenPorch$\"\n",
      "    features: \"^Street$\"\n",
      "    features: \"^TotRmsAbvGrd$\"\n",
      "    features: \"^TotalBsmtSF$\"\n",
      "    features: \"^Utilities$\"\n",
      "    features: \"^WoodDeckSF$\"\n",
      "    features: \"^YearBuilt$\"\n",
      "    features: \"^YearRemodAdd$\"\n",
      "    features: \"^YrSold$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: REGRESSION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 6\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: -1\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      shrinkage: 0.1\n",
      "      loss: DEFAULT\n",
      "      validation_set_ratio: 0.1\n",
      "      validation_interval_in_trees: 1\n",
      "      early_stopping: VALIDATION_LOSS_INCREASE\n",
      "      early_stopping_num_trees_look_ahead: 30\n",
      "      l2_regularization: 0\n",
      "      lambda_loss: 1\n",
      "      mart {\n",
      "      }\n",
      "      adapt_subsample_for_maximum_training_duration: false\n",
      "      l1_regularization: 0\n",
      "      use_hessian_gain: false\n",
      "      l2_regularization_categorical: 1\n",
      "      xe_ndcg {\n",
      "        ndcg_truncation: 5\n",
      "      }\n",
      "      stochastic_gradient_boosting {\n",
      "        ratio: 1\n",
      "      }\n",
      "      apply_link_function: true\n",
      "      compute_permutation_variable_importance: false\n",
      "      early_stopping_initial_iteration: 10\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 10\n",
      "    }\n",
      "  }\n",
      "  search_space {\n",
      "    fields {\n",
      "      name: \"num_trees\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 50\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 200\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 500\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"shrinkage\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          real: 0.01\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.1\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.3\n",
      "        }\n",
      "        possible_values {\n",
      "          real: 0.5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"max_depth\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 4\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 6\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 10\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"min_examples\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 2\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 5\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 10\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "I0000 00:00:1736216857.865926 35735652 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmplu8yr3q4/working_cache\"\n",
      "num_threads: 10\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1736216857.865978 35797270 kernel.cc:895] Train model\n",
      "2025-01-06 21:27:37.866334: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:210] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"num_trees\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 50\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 200\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 500\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      real: 0.01\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.1\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.3\n",
      "    }\n",
      "    possible_values {\n",
      "      real: 0.5\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 4\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 6\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 2\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2025-01-06 21:27:37.866348: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:494] Start local tuner with 1 parallel trial(s), each with 10 thread(s)\n",
      "2025-01-06 21:27:37.866781: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:37.866790: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:37.867452: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:37.877731: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.206570 train-rmse:0.206570 valid-loss:0.260213 valid-rmse:0.260213\n",
      "2025-01-06 21:27:37.886603: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1605] \tnum-trees:2 train-loss:0.110051 train-rmse:0.110051 valid-loss:0.204686 valid-rmse:0.204686\n",
      "I0000 00:00:1736216858.148383 35797271 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.181258\n",
      "2025-01-06 21:27:38.148414: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 12 tree(s) i.e. 12  iteration(s).\n",
      "2025-01-06 21:27:38.148907: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:12 valid-loss:0.181258 valid-rmse:0.181258\n",
      "2025-01-06 21:27:38.149903: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [1/10] Score: -0.181258 / -0.181258 HParams: fields { name: \"num_trees\" value { integer: 50 } } fields { name: \"shrinkage\" value { real: 0.5 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "2025-01-06 21:27:38.150207: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:38.150218: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:38.150772: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:38.154258: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.314597 train-rmse:0.314597 valid-loss:0.341675 valid-rmse:0.341675\n",
      "2025-01-06 21:27:38.227480: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:50 train-loss:0.067357 train-rmse:0.067357 valid-loss:0.155443 valid-rmse:0.155443\n",
      "2025-01-06 21:27:38.227498: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 48 tree(s) i.e. 48  iteration(s).\n",
      "2025-01-06 21:27:38.227503: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:48 valid-loss:0.154156 valid-rmse:0.154156\n",
      "2025-01-06 21:27:38.228059: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:38.228066: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:38.228152: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [2/10] Score: -0.154156 / -0.154156 HParams: fields { name: \"num_trees\" value { integer: 50 } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "2025-01-06 21:27:38.228615: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:38.236721: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.224958 train-rmse:0.224958 valid-loss:0.264642 valid-rmse:0.264642\n",
      "I0000 00:00:1736216858.544027 35797271 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.174421\n",
      "2025-01-06 21:27:38.544049: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 26 tree(s) i.e. 26  iteration(s).\n",
      "2025-01-06 21:27:38.544286: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:26 valid-loss:0.174421 valid-rmse:0.174421\n",
      "2025-01-06 21:27:38.544961: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [3/10] Score: -0.174421 / -0.154156 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"shrinkage\" value { real: 0.5 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "2025-01-06 21:27:38.545275: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:38.545285: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:38.545838: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:38.549264: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.266815 train-rmse:0.266815 valid-loss:0.299101 valid-rmse:0.299101\n",
      "2025-01-06 21:27:38.622559: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:50 train-loss:0.047739 train-rmse:0.047739 valid-loss:0.170013 valid-rmse:0.170013\n",
      "2025-01-06 21:27:38.622569: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 29 tree(s) i.e. 29  iteration(s).\n",
      "2025-01-06 21:27:38.622595: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:29 valid-loss:0.164403 valid-rmse:0.164403\n",
      "2025-01-06 21:27:38.622814: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [4/10] Score: -0.164403 / -0.154156 HParams: fields { name: \"num_trees\" value { integer: 50 } } fields { name: \"shrinkage\" value { real: 0.5 } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "2025-01-06 21:27:38.623111: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:38.623117: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:38.623655: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:38.632731: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.285810 train-rmse:0.285810 valid-loss:0.317786 valid-rmse:0.317786\n",
      "2025-01-06 21:27:38.923701: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:50 train-loss:0.003151 train-rmse:0.003151 valid-loss:0.181364 valid-rmse:0.181364\n",
      "2025-01-06 21:27:38.923721: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 27 tree(s) i.e. 27  iteration(s).\n",
      "2025-01-06 21:27:38.923969: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:27 valid-loss:0.181080 valid-rmse:0.181080\n",
      "2025-01-06 21:27:38.924958: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [5/10] Score: -0.18108 / -0.154156 HParams: fields { name: \"num_trees\" value { integer: 50 } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "2025-01-06 21:27:38.925275: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:38.925283: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:38.925845: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:38.929287: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.368800 train-rmse:0.368800 valid-loss:0.390858 valid-rmse:0.390858\n",
      "I0000 00:00:1736216859.105285 35797271 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.152214\n",
      "2025-01-06 21:27:39.105306: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 84 tree(s) i.e. 84  iteration(s).\n",
      "2025-01-06 21:27:39.105337: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:84 valid-loss:0.152214 valid-rmse:0.152214\n",
      "2025-01-06 21:27:39.105807: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [6/10] Score: -0.152214 / -0.152214 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"max_depth\" value { integer: 4 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "2025-01-06 21:27:39.106023: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:39.106033: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:39.106588: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:39.111852: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.297363 train-rmse:0.297363 valid-loss:0.317827 valid-rmse:0.317827\n",
      "I0000 00:00:1736216859.244193 35797271 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.140887\n",
      "2025-01-06 21:27:39.244215: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 16 tree(s) i.e. 16  iteration(s).\n",
      "2025-01-06 21:27:39.244326: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:16 valid-loss:0.140887 valid-rmse:0.140887\n",
      "2025-01-06 21:27:39.244781: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [7/10] Score: -0.140887 / -0.140887 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"shrinkage\" value { real: 0.3 } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "2025-01-06 21:27:39.244950: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:39.244957: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:39.245529: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:39.256765: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.358871 train-rmse:0.358871 valid-loss:0.382112 valid-rmse:0.382112\n",
      "2025-01-06 21:27:39.685176: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:50 train-loss:0.005044 train-rmse:0.005044 valid-loss:0.178216 valid-rmse:0.178216\n",
      "2025-01-06 21:27:39.685192: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 50 tree(s) i.e. 50  iteration(s).\n",
      "2025-01-06 21:27:39.685195: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:50 valid-loss:0.178216 valid-rmse:0.178216\n",
      "2025-01-06 21:27:39.689516: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [8/10] Score: -0.178216 / -0.140887 HParams: fields { name: \"num_trees\" value { integer: 50 } } fields { name: \"shrinkage\" value { real: 0.1 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "2025-01-06 21:27:39.689831: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:39.689840: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:39.690407: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:39.698533: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.393900 train-rmse:0.393900 valid-loss:0.413733 valid-rmse:0.413733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:04.972681\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736216862.683145 35797271 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.160102\n",
      "2025-01-06 21:27:42.683174: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 432 tree(s) i.e. 432  iteration(s).\n",
      "2025-01-06 21:27:42.683377: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:432 valid-loss:0.160102 valid-rmse:0.160102\n",
      "2025-01-06 21:27:42.693349: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [9/10] Score: -0.160102 / -0.140887 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"shrinkage\" value { real: 0.01 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "2025-01-06 21:27:42.693651: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:575] Default loss set to SQUARED_ERROR\n",
      "2025-01-06 21:27:42.693658: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1188] Training gradient boosted tree on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:42.694229: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1228] 1078 examples used for training and 87 examples used for validation\n",
      "2025-01-06 21:27:42.699674: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1603] \tnum-trees:1 train-loss:0.235968 train-rmse:0.235968 valid-loss:0.263154 valid-rmse:0.263154\n",
      "I0000 00:00:1736216862.812604 35797271 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.180245\n",
      "2025-01-06 21:27:42.812624: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:277] Truncates the model to 11 tree(s) i.e. 11  iteration(s).\n",
      "2025-01-06 21:27:42.812740: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:297] The best validation loss was obtained during iteration 10. This is the first step during which a validation loss was computed, hence the validation loss might still have been unstable and not optimal. Following are examples of hyper-parameter changes that might help with the situation. Try them in order: (1) Decrease the 'shrinkage rate' parameter (default value of 0.1). For example divide its value by 2. (2) Decrease the 'num_candidate_attributes_ratio' hyper-parameter (default value of 1) by 80%. (3) Increase the early_stopping_num_trees_look_ahead parameter (e.g., try multiplying it by a factor of 2). (4) Use a more expensive but stable version of early stopping with 'early_stopping=MIN_LOSS_FINAL'. (4) Disable early stopping completely with 'early_stopping=NONE'.\n",
      "2025-01-06 21:27:42.812744: I external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:339] Final model num-trees:11 valid-loss:0.180245 valid-rmse:0.180245\n",
      "2025-01-06 21:27:42.813009: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [10/10] Score: -0.180245 / -0.140887 HParams: fields { name: \"num_trees\" value { integer: 50 } } fields { name: \"shrinkage\" value { real: 0.5 } } fields { name: \"max_depth\" value { integer: 6 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "2025-01-06 21:27:42.813166: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"num_trees\"\n",
      "  value {\n",
      "    integer: 200\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"shrinkage\"\n",
      "  value {\n",
      "    real: 0.3\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  value {\n",
      "    integer: 6\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 5\n",
      "  }\n",
      "}\n",
      "\n",
      "I0000 00:00:1736216862.813242 35797270 kernel.cc:926] Export model in log directory: /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmplu8yr3q4 with prefix 871a119d4d684bea\n",
      "I0000 00:00:1736216862.814345 35797270 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1736216862.815097 35735652 abstract_model.cc:914] Model self evaluation:\n",
      "Number of predictions (with weights): 1\n",
      "Task: REGRESSION\n",
      "Loss (SQUARED_ERROR): 0.140887\n",
      "\n",
      "RMSE: 0.375349\n",
      "Default RMSE: : 0\n",
      "\n",
      "2025-01-06 21:27:42.833316: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmplu8yr3q4/model/ with prefix 871a119d4d684bea\n",
      "I0000 00:00:1736216862.834583 35735652 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "2025-01-06 21:27:42.834597: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Use /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpqkkn4nb2 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.307681. Found 1165 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736216863.433683 35735652 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1736216863.433699 35735652 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1736216863.433705 35735652 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: NUMERICAL\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1736216863.433835 35735652 kernel.cc:401] Number of batches: 2\n",
      "I0000 00:00:1736216863.433840 35735652 kernel.cc:402] Number of examples: 1165\n",
      "I0000 00:00:1736216863.434875 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column BsmtCond (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434886 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Condition1 (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434889 35735652 data_spec_inference.cc:354] 6 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Condition2 (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434892 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Electrical (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434894 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column ExterCond (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434898 35735652 data_spec_inference.cc:354] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Exterior1st (10 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434902 35735652 data_spec_inference.cc:354] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Exterior2nd (12 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434907 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Foundation (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434910 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Functional (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434912 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column GarageCond (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434917 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column GarageQual (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434919 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column GarageType (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434922 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Heating (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434925 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column HeatingQC (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434932 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column LotConfig (4 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434938 35735652 data_spec_inference.cc:354] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column MiscFeature (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434941 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Neighborhood (24 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434947 35735652 data_spec_inference.cc:354] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column PoolQC (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434949 35735652 data_spec_inference.cc:354] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column RoofMatl (3 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434952 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column RoofStyle (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434955 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column SaleCondition (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434958 35735652 data_spec_inference.cc:354] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column SaleType (5 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434961 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Street (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.434963 35735652 data_spec_inference.cc:354] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Utilities (1 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1736216863.435743 35735652 kernel.cc:802] Training dataset:\n",
      "Number of records: 1165\n",
      "Number of columns: 81\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 43 (53.0864%)\n",
      "\tNUMERICAL: 38 (46.9136%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 43 (53.0864%)\n",
      "\t3: \"Alley\" CATEGORICAL num-nas:1096 (94.0773%) has-dict vocab-size:3 zero-ood-items most-frequent:\"Grvl\" 37 (53.6232%)\n",
      "\t5: \"BldgType\" CATEGORICAL has-dict vocab-size:6 zero-ood-items most-frequent:\"1Fam\" 976 (83.7768%)\n",
      "\t6: \"BsmtCond\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:4 num-oods:2 (0.175285%) most-frequent:\"TA\" 1052 (92.1998%)\n",
      "\t7: \"BsmtExposure\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:5 zero-ood-items most-frequent:\"No\" 759 (66.5206%)\n",
      "\t10: \"BsmtFinType1\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:7 zero-ood-items most-frequent:\"Unf\" 346 (30.3243%)\n",
      "\t11: \"BsmtFinType2\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:7 zero-ood-items most-frequent:\"Unf\" 1005 (88.0806%)\n",
      "\t14: \"BsmtQual\" CATEGORICAL num-nas:24 (2.06009%) has-dict vocab-size:5 zero-ood-items most-frequent:\"TA\" 518 (45.3988%)\n",
      "\t16: \"CentralAir\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"Y\" 1097 (94.1631%)\n",
      "\t17: \"Condition1\" CATEGORICAL has-dict vocab-size:8 num-oods:4 (0.343348%) most-frequent:\"Norm\" 1010 (86.6953%)\n",
      "\t18: \"Condition2\" CATEGORICAL has-dict vocab-size:2 num-oods:11 (0.944206%) most-frequent:\"Norm\" 1154 (99.0558%)\n",
      "\t19: \"Electrical\" CATEGORICAL has-dict vocab-size:4 num-oods:2 (0.171674%) most-frequent:\"SBrkr\" 1071 (91.9313%)\n",
      "\t21: \"ExterCond\" CATEGORICAL has-dict vocab-size:4 num-oods:4 (0.343348%) most-frequent:\"TA\" 1022 (87.7253%)\n",
      "\t22: \"ExterQual\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"TA\" 712 (61.1159%)\n",
      "\t23: \"Exterior1st\" CATEGORICAL has-dict vocab-size:11 num-oods:3 (0.257511%) most-frequent:\"VinylSd\" 421 (36.1373%)\n",
      "\t24: \"Exterior2nd\" CATEGORICAL has-dict vocab-size:13 num-oods:7 (0.600858%) most-frequent:\"VinylSd\" 412 (35.3648%)\n",
      "\t25: \"Fence\" CATEGORICAL num-nas:945 (81.1159%) has-dict vocab-size:5 zero-ood-items most-frequent:\"MnPrv\" 123 (55.9091%)\n",
      "\t26: \"FireplaceQu\" CATEGORICAL num-nas:544 (46.6953%) has-dict vocab-size:6 zero-ood-items most-frequent:\"Gd\" 312 (50.2415%)\n",
      "\t28: \"Foundation\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.600858%) most-frequent:\"PConc\" 524 (44.9785%)\n",
      "\t30: \"Functional\" CATEGORICAL has-dict vocab-size:7 num-oods:1 (0.0858369%) most-frequent:\"Typ\" 1084 (93.0472%)\n",
      "\t33: \"GarageCond\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:5 num-oods:1 (0.0914913%) most-frequent:\"TA\" 1050 (96.0659%)\n",
      "\t34: \"GarageFinish\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:4 zero-ood-items most-frequent:\"Unf\" 460 (42.086%)\n",
      "\t35: \"GarageQual\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:4 num-oods:5 (0.457457%) most-frequent:\"TA\" 1040 (95.151%)\n",
      "\t36: \"GarageType\" CATEGORICAL num-nas:72 (6.18026%) has-dict vocab-size:6 num-oods:3 (0.274474%) most-frequent:\"Attchd\" 696 (63.678%)\n",
      "\t40: \"Heating\" CATEGORICAL has-dict vocab-size:4 num-oods:5 (0.429185%) most-frequent:\"GasA\" 1139 (97.7682%)\n",
      "\t41: \"HeatingQC\" CATEGORICAL has-dict vocab-size:5 num-oods:1 (0.0858369%) most-frequent:\"Ex\" 596 (51.1588%)\n",
      "\t42: \"HouseStyle\" CATEGORICAL has-dict vocab-size:9 zero-ood-items most-frequent:\"1Story\" 575 (49.3562%)\n",
      "\t45: \"KitchenQual\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"TA\" 581 (49.8712%)\n",
      "\t46: \"LandContour\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"Lvl\" 1042 (89.4421%)\n",
      "\t47: \"LandSlope\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Gtl\" 1102 (94.5923%)\n",
      "\t49: \"LotConfig\" CATEGORICAL has-dict vocab-size:5 num-oods:4 (0.343348%) most-frequent:\"Inside\" 836 (71.7597%)\n",
      "\t51: \"LotShape\" CATEGORICAL has-dict vocab-size:5 zero-ood-items most-frequent:\"Reg\" 734 (63.0043%)\n",
      "\t54: \"MSZoning\" CATEGORICAL has-dict vocab-size:6 zero-ood-items most-frequent:\"RL\" 920 (78.97%)\n",
      "\t56: \"MasVnrType\" CATEGORICAL num-nas:689 (59.1416%) has-dict vocab-size:4 zero-ood-items most-frequent:\"BrkFace\" 356 (74.7899%)\n",
      "\t57: \"MiscFeature\" CATEGORICAL num-nas:1122 (96.309%) has-dict vocab-size:2 num-oods:4 (9.30233%) most-frequent:\"Shed\" 39 (90.6977%)\n",
      "\t60: \"Neighborhood\" CATEGORICAL has-dict vocab-size:25 num-oods:2 (0.171674%) most-frequent:\"NAmes\" 183 (15.7082%)\n",
      "\t64: \"PavedDrive\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Y\" 1071 (91.9313%)\n",
      "\t66: \"PoolQC\" CATEGORICAL num-nas:1161 (99.6567%) has-dict vocab-size:1 num-oods:4 (100%)\n",
      "\t67: \"RoofMatl\" CATEGORICAL has-dict vocab-size:4 num-oods:5 (0.429185%) most-frequent:\"CompShg\" 1146 (98.3691%)\n",
      "\t68: \"RoofStyle\" CATEGORICAL has-dict vocab-size:6 num-oods:2 (0.171674%) most-frequent:\"Gable\" 903 (77.5107%)\n",
      "\t69: \"SaleCondition\" CATEGORICAL has-dict vocab-size:6 num-oods:2 (0.171674%) most-frequent:\"Normal\" 951 (81.6309%)\n",
      "\t70: \"SaleType\" CATEGORICAL has-dict vocab-size:6 num-oods:11 (0.944206%) most-frequent:\"WD\" 1004 (86.1803%)\n",
      "\t72: \"Street\" CATEGORICAL has-dict vocab-size:2 num-oods:4 (0.343348%) most-frequent:\"Pave\" 1161 (99.6567%)\n",
      "\t75: \"Utilities\" CATEGORICAL has-dict vocab-size:2 num-oods:1 (0.0858369%) most-frequent:\"AllPub\" 1164 (99.9142%)\n",
      "\n",
      "NUMERICAL: 38 (46.9136%)\n",
      "\t0: \"1stFlrSF\" NUMERICAL mean:1163.62 min:372 max:4692 sd:390.377\n",
      "\t1: \"2ndFlrSF\" NUMERICAL mean:354.442 min:0 max:1872 sd:442.352\n",
      "\t2: \"3SsnPorch\" NUMERICAL mean:3.25322 min:0 max:508 sd:28.2724\n",
      "\t4: \"BedroomAbvGr\" NUMERICAL mean:2.8824 min:0 max:8 sd:0.819761\n",
      "\t8: \"BsmtFinSF1\" NUMERICAL mean:448.565 min:0 max:5644 sd:460.659\n",
      "\t9: \"BsmtFinSF2\" NUMERICAL mean:46.9202 min:0 max:1127 sd:160.976\n",
      "\t12: \"BsmtFullBath\" NUMERICAL mean:0.427468 min:0 max:3 sd:0.518434\n",
      "\t13: \"BsmtHalfBath\" NUMERICAL mean:0.0609442 min:0 max:2 sd:0.2463\n",
      "\t15: \"BsmtUnfSF\" NUMERICAL mean:565.572 min:0 max:2336 sd:435.502\n",
      "\t20: \"EnclosedPorch\" NUMERICAL mean:22.1382 min:0 max:552 sd:61.1196\n",
      "\t27: \"Fireplaces\" NUMERICAL mean:0.616309 min:0 max:3 sd:0.638863\n",
      "\t29: \"FullBath\" NUMERICAL mean:1.57425 min:0 max:3 sd:0.554983\n",
      "\t31: \"GarageArea\" NUMERICAL mean:471.641 min:0 max:1418 sd:218.173\n",
      "\t32: \"GarageCars\" NUMERICAL mean:1.76223 min:0 max:4 sd:0.759002\n",
      "\t37: \"GarageYrBlt\" NUMERICAL num-nas:72 (6.18026%) mean:1978.74 min:1900 max:2010 sd:24.8408\n",
      "\t38: \"GrLivArea\" NUMERICAL mean:1524.08 min:438 max:5642 sd:530.529\n",
      "\t39: \"HalfBath\" NUMERICAL mean:0.387124 min:0 max:2 sd:0.502702\n",
      "\t43: \"Id\" NUMERICAL mean:742.477 min:1 max:1460 sd:419.979\n",
      "\t44: \"KitchenAbvGr\" NUMERICAL mean:1.04464 min:0 max:3 sd:0.218616\n",
      "\t48: \"LotArea\" NUMERICAL mean:10582.5 min:1300 max:215245 sd:10340.4\n",
      "\t50: \"LotFrontage\" NUMERICAL mean:69.8532 min:21 max:313 sd:22.4105\n",
      "\t52: \"LowQualFinSF\" NUMERICAL mean:6.0206 min:0 max:572 sd:49.4899\n",
      "\t53: \"MSSubClass\" NUMERICAL mean:57.1202 min:20 max:190 sd:42.3212\n",
      "\t55: \"MasVnrArea\" NUMERICAL num-nas:6 (0.515021%) mean:107.459 min:0 max:1600 sd:185.966\n",
      "\t58: \"MiscVal\" NUMERICAL mean:44.3468 min:0 max:15500 sd:540.007\n",
      "\t59: \"MoSold\" NUMERICAL mean:6.36052 min:1 max:12 sd:2.66637\n",
      "\t61: \"OpenPorchSF\" NUMERICAL mean:47.206 min:0 max:547 sd:66.9365\n",
      "\t62: \"OverallCond\" NUMERICAL mean:5.58627 min:1 max:9 sd:1.12123\n",
      "\t63: \"OverallQual\" NUMERICAL mean:6.13047 min:1 max:10 sd:1.39409\n",
      "\t65: \"PoolArea\" NUMERICAL mean:1.90215 min:0 max:648 sd:32.6249\n",
      "\t71: \"ScreenPorch\" NUMERICAL mean:14.9167 min:0 max:480 sd:55.1891\n",
      "\t73: \"TotRmsAbvGrd\" NUMERICAL mean:6.56052 min:3 max:14 sd:1.64929\n",
      "\t74: \"TotalBsmtSF\" NUMERICAL mean:1061.06 min:0 max:6110 sd:433.612\n",
      "\t76: \"WoodDeckSF\" NUMERICAL mean:94.7476 min:0 max:857 sd:123.707\n",
      "\t77: \"YearBuilt\" NUMERICAL mean:1971.39 min:1872 max:2010 sd:30.5351\n",
      "\t78: \"YearRemodAdd\" NUMERICAL mean:1985.28 min:1950 max:2010 sd:20.5411\n",
      "\t79: \"YrSold\" NUMERICAL mean:2007.82 min:2006 max:2010 sd:1.33018\n",
      "\t80: \"__LABEL\" NUMERICAL mean:12.0314 min:10.4602 max:13.5345 sd:0.398999\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1736216863.435790 35735652 kernel.cc:818] Configure learner\n",
      "I0000 00:00:1736216863.435947 35735652 kernel.cc:831] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^1stFlrSF$\"\n",
      "features: \"^2ndFlrSF$\"\n",
      "features: \"^3SsnPorch$\"\n",
      "features: \"^Alley$\"\n",
      "features: \"^BedroomAbvGr$\"\n",
      "features: \"^BldgType$\"\n",
      "features: \"^BsmtCond$\"\n",
      "features: \"^BsmtExposure$\"\n",
      "features: \"^BsmtFinSF1$\"\n",
      "features: \"^BsmtFinSF2$\"\n",
      "features: \"^BsmtFinType1$\"\n",
      "features: \"^BsmtFinType2$\"\n",
      "features: \"^BsmtFullBath$\"\n",
      "features: \"^BsmtHalfBath$\"\n",
      "features: \"^BsmtQual$\"\n",
      "features: \"^BsmtUnfSF$\"\n",
      "features: \"^CentralAir$\"\n",
      "features: \"^Condition1$\"\n",
      "features: \"^Condition2$\"\n",
      "features: \"^Electrical$\"\n",
      "features: \"^EnclosedPorch$\"\n",
      "features: \"^ExterCond$\"\n",
      "features: \"^ExterQual$\"\n",
      "features: \"^Exterior1st$\"\n",
      "features: \"^Exterior2nd$\"\n",
      "features: \"^Fence$\"\n",
      "features: \"^FireplaceQu$\"\n",
      "features: \"^Fireplaces$\"\n",
      "features: \"^Foundation$\"\n",
      "features: \"^FullBath$\"\n",
      "features: \"^Functional$\"\n",
      "features: \"^GarageArea$\"\n",
      "features: \"^GarageCars$\"\n",
      "features: \"^GarageCond$\"\n",
      "features: \"^GarageFinish$\"\n",
      "features: \"^GarageQual$\"\n",
      "features: \"^GarageType$\"\n",
      "features: \"^GarageYrBlt$\"\n",
      "features: \"^GrLivArea$\"\n",
      "features: \"^HalfBath$\"\n",
      "features: \"^Heating$\"\n",
      "features: \"^HeatingQC$\"\n",
      "features: \"^HouseStyle$\"\n",
      "features: \"^Id$\"\n",
      "features: \"^KitchenAbvGr$\"\n",
      "features: \"^KitchenQual$\"\n",
      "features: \"^LandContour$\"\n",
      "features: \"^LandSlope$\"\n",
      "features: \"^LotArea$\"\n",
      "features: \"^LotConfig$\"\n",
      "features: \"^LotFrontage$\"\n",
      "features: \"^LotShape$\"\n",
      "features: \"^LowQualFinSF$\"\n",
      "features: \"^MSSubClass$\"\n",
      "features: \"^MSZoning$\"\n",
      "features: \"^MasVnrArea$\"\n",
      "features: \"^MasVnrType$\"\n",
      "features: \"^MiscFeature$\"\n",
      "features: \"^MiscVal$\"\n",
      "features: \"^MoSold$\"\n",
      "features: \"^Neighborhood$\"\n",
      "features: \"^OpenPorchSF$\"\n",
      "features: \"^OverallCond$\"\n",
      "features: \"^OverallQual$\"\n",
      "features: \"^PavedDrive$\"\n",
      "features: \"^PoolArea$\"\n",
      "features: \"^PoolQC$\"\n",
      "features: \"^RoofMatl$\"\n",
      "features: \"^RoofStyle$\"\n",
      "features: \"^SaleCondition$\"\n",
      "features: \"^SaleType$\"\n",
      "features: \"^ScreenPorch$\"\n",
      "features: \"^Street$\"\n",
      "features: \"^TotRmsAbvGrd$\"\n",
      "features: \"^TotalBsmtSF$\"\n",
      "features: \"^Utilities$\"\n",
      "features: \"^WoodDeckSF$\"\n",
      "features: \"^YearBuilt$\"\n",
      "features: \"^YearRemodAdd$\"\n",
      "features: \"^YrSold$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: REGRESSION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"RANDOM_FOREST\"\n",
      "    features: \"^1stFlrSF$\"\n",
      "    features: \"^2ndFlrSF$\"\n",
      "    features: \"^3SsnPorch$\"\n",
      "    features: \"^Alley$\"\n",
      "    features: \"^BedroomAbvGr$\"\n",
      "    features: \"^BldgType$\"\n",
      "    features: \"^BsmtCond$\"\n",
      "    features: \"^BsmtExposure$\"\n",
      "    features: \"^BsmtFinSF1$\"\n",
      "    features: \"^BsmtFinSF2$\"\n",
      "    features: \"^BsmtFinType1$\"\n",
      "    features: \"^BsmtFinType2$\"\n",
      "    features: \"^BsmtFullBath$\"\n",
      "    features: \"^BsmtHalfBath$\"\n",
      "    features: \"^BsmtQual$\"\n",
      "    features: \"^BsmtUnfSF$\"\n",
      "    features: \"^CentralAir$\"\n",
      "    features: \"^Condition1$\"\n",
      "    features: \"^Condition2$\"\n",
      "    features: \"^Electrical$\"\n",
      "    features: \"^EnclosedPorch$\"\n",
      "    features: \"^ExterCond$\"\n",
      "    features: \"^ExterQual$\"\n",
      "    features: \"^Exterior1st$\"\n",
      "    features: \"^Exterior2nd$\"\n",
      "    features: \"^Fence$\"\n",
      "    features: \"^FireplaceQu$\"\n",
      "    features: \"^Fireplaces$\"\n",
      "    features: \"^Foundation$\"\n",
      "    features: \"^FullBath$\"\n",
      "    features: \"^Functional$\"\n",
      "    features: \"^GarageArea$\"\n",
      "    features: \"^GarageCars$\"\n",
      "    features: \"^GarageCond$\"\n",
      "    features: \"^GarageFinish$\"\n",
      "    features: \"^GarageQual$\"\n",
      "    features: \"^GarageType$\"\n",
      "    features: \"^GarageYrBlt$\"\n",
      "    features: \"^GrLivArea$\"\n",
      "    features: \"^HalfBath$\"\n",
      "    features: \"^Heating$\"\n",
      "    features: \"^HeatingQC$\"\n",
      "    features: \"^HouseStyle$\"\n",
      "    features: \"^Id$\"\n",
      "    features: \"^KitchenAbvGr$\"\n",
      "    features: \"^KitchenQual$\"\n",
      "    features: \"^LandContour$\"\n",
      "    features: \"^LandSlope$\"\n",
      "    features: \"^LotArea$\"\n",
      "    features: \"^LotConfig$\"\n",
      "    features: \"^LotFrontage$\"\n",
      "    features: \"^LotShape$\"\n",
      "    features: \"^LowQualFinSF$\"\n",
      "    features: \"^MSSubClass$\"\n",
      "    features: \"^MSZoning$\"\n",
      "    features: \"^MasVnrArea$\"\n",
      "    features: \"^MasVnrType$\"\n",
      "    features: \"^MiscFeature$\"\n",
      "    features: \"^MiscVal$\"\n",
      "    features: \"^MoSold$\"\n",
      "    features: \"^Neighborhood$\"\n",
      "    features: \"^OpenPorchSF$\"\n",
      "    features: \"^OverallCond$\"\n",
      "    features: \"^OverallQual$\"\n",
      "    features: \"^PavedDrive$\"\n",
      "    features: \"^PoolArea$\"\n",
      "    features: \"^PoolQC$\"\n",
      "    features: \"^RoofMatl$\"\n",
      "    features: \"^RoofStyle$\"\n",
      "    features: \"^SaleCondition$\"\n",
      "    features: \"^SaleType$\"\n",
      "    features: \"^ScreenPorch$\"\n",
      "    features: \"^Street$\"\n",
      "    features: \"^TotRmsAbvGrd$\"\n",
      "    features: \"^TotalBsmtSF$\"\n",
      "    features: \"^Utilities$\"\n",
      "    features: \"^WoodDeckSF$\"\n",
      "    features: \"^YearBuilt$\"\n",
      "    features: \"^YearRemodAdd$\"\n",
      "    features: \"^YrSold$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: REGRESSION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 16\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: 0\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "      }\n",
      "      winner_take_all_inference: true\n",
      "      compute_oob_performances: true\n",
      "      compute_oob_variable_importances: false\n",
      "      num_oob_variable_importances_permutations: 1\n",
      "      bootstrap_training_dataset: true\n",
      "      bootstrap_size_ratio: 1\n",
      "      adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "      sampling_with_replacement: true\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 20\n",
      "    }\n",
      "  }\n",
      "  search_space {\n",
      "    fields {\n",
      "      name: \"num_trees\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 100\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 200\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 500\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"max_depth\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: -1\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 10\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 30\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    fields {\n",
      "      name: \"min_examples\"\n",
      "      discrete_candidates {\n",
      "        possible_values {\n",
      "          integer: 2\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 5\n",
      "        }\n",
      "        possible_values {\n",
      "          integer: 10\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "I0000 00:00:1736216863.436002 35735652 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpqkkn4nb2/working_cache\"\n",
      "num_threads: 10\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1736216863.436086 35797557 kernel.cc:895] Train model\n",
      "2025-01-06 21:27:43.436463: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:210] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"num_trees\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 100\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 200\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 500\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: -1\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 30\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 2\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2025-01-06 21:27:43.436479: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:494] Start local tuner with 1 parallel trial(s), each with 10 thread(s)\n",
      "I0000 00:00:1736216863.436887 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216863.443545 35797560 random_forest.cc:811] Training of tree  1/100 (tree index:0) done rmse:0.205591\n",
      "I0000 00:00:1736216863.490545 35797560 random_forest.cc:811] Training of tree  11/100 (tree index:10) done rmse:0.164376\n",
      "I0000 00:00:1736216863.537663 35797560 random_forest.cc:811] Training of tree  21/100 (tree index:20) done rmse:0.153089\n",
      "I0000 00:00:1736216863.584063 35797560 random_forest.cc:811] Training of tree  31/100 (tree index:30) done rmse:0.146778\n",
      "I0000 00:00:1736216863.629973 35797560 random_forest.cc:811] Training of tree  41/100 (tree index:40) done rmse:0.14597\n",
      "I0000 00:00:1736216863.676273 35797560 random_forest.cc:811] Training of tree  51/100 (tree index:50) done rmse:0.144875\n",
      "I0000 00:00:1736216863.722681 35797560 random_forest.cc:811] Training of tree  61/100 (tree index:60) done rmse:0.144789\n",
      "I0000 00:00:1736216863.768911 35797560 random_forest.cc:811] Training of tree  71/100 (tree index:70) done rmse:0.144079\n",
      "I0000 00:00:1736216863.814788 35797560 random_forest.cc:811] Training of tree  81/100 (tree index:80) done rmse:0.144381\n",
      "I0000 00:00:1736216863.860335 35797560 random_forest.cc:811] Training of tree  91/100 (tree index:90) done rmse:0.144205\n",
      "I0000 00:00:1736216863.900810 35797560 random_forest.cc:811] Training of tree  100/100 (tree index:99) done rmse:0.143687\n",
      "I0000 00:00:1736216863.900858 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.143687\n",
      "2025-01-06 21:27:43.904535: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [1/20] Score: -0.143687 / -0.143687 HParams: fields { name: \"num_trees\" value { integer: 100 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "I0000 00:00:1736216863.904923 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216863.912715 35797562 random_forest.cc:811] Training of tree  1/100 (tree index:0) done rmse:0.202854\n",
      "I0000 00:00:1736216863.972271 35797562 random_forest.cc:811] Training of tree  11/100 (tree index:10) done rmse:0.168443\n",
      "I0000 00:00:1736216864.031757 35797562 random_forest.cc:811] Training of tree  21/100 (tree index:20) done rmse:0.152315\n",
      "I0000 00:00:1736216864.091990 35797562 random_forest.cc:811] Training of tree  31/100 (tree index:30) done rmse:0.147728\n",
      "I0000 00:00:1736216864.154137 35797562 random_forest.cc:811] Training of tree  41/100 (tree index:40) done rmse:0.144086\n",
      "I0000 00:00:1736216864.215024 35797562 random_forest.cc:811] Training of tree  51/100 (tree index:50) done rmse:0.143011\n",
      "I0000 00:00:1736216864.275319 35797562 random_forest.cc:811] Training of tree  61/100 (tree index:60) done rmse:0.142305\n",
      "I0000 00:00:1736216864.336187 35797562 random_forest.cc:811] Training of tree  71/100 (tree index:70) done rmse:0.141454\n",
      "I0000 00:00:1736216864.396420 35797562 random_forest.cc:811] Training of tree  81/100 (tree index:80) done rmse:0.141248\n",
      "I0000 00:00:1736216864.456161 35797562 random_forest.cc:811] Training of tree  91/100 (tree index:90) done rmse:0.140506\n",
      "I0000 00:00:1736216864.510657 35797562 random_forest.cc:811] Training of tree  100/100 (tree index:99) done rmse:0.140873\n",
      "I0000 00:00:1736216864.510706 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.140873\n",
      "I0000 00:00:1736216864.519191 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:44.520544: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [2/20] Score: -0.140873 / -0.140873 HParams: fields { name: \"num_trees\" value { integer: 100 } } fields { name: \"max_depth\" value { integer: -1 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "I0000 00:00:1736216864.525657 35797585 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.205591\n",
      "I0000 00:00:1736216864.571274 35797585 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.164376\n",
      "I0000 00:00:1736216864.616592 35797585 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.153089\n",
      "I0000 00:00:1736216864.662879 35797585 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.146778\n",
      "I0000 00:00:1736216864.709312 35797585 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.14597\n",
      "I0000 00:00:1736216864.755104 35797585 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.144875\n",
      "I0000 00:00:1736216864.800641 35797585 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.144789\n",
      "I0000 00:00:1736216864.846380 35797585 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.144079\n",
      "I0000 00:00:1736216864.893654 35797585 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.144381\n",
      "I0000 00:00:1736216864.940628 35797585 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.144205\n",
      "I0000 00:00:1736216864.987325 35797585 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.143531\n",
      "I0000 00:00:1736216865.033657 35797585 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.142995\n",
      "I0000 00:00:1736216865.080059 35797585 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.142692\n",
      "I0000 00:00:1736216865.126229 35797585 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.142352\n",
      "I0000 00:00:1736216865.172849 35797585 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.142192\n",
      "I0000 00:00:1736216865.219486 35797585 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.141775\n",
      "I0000 00:00:1736216865.266676 35797585 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.141641\n",
      "I0000 00:00:1736216865.313073 35797585 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.141786\n",
      "I0000 00:00:1736216865.359958 35797585 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.141871\n",
      "I0000 00:00:1736216865.406153 35797585 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.141598\n",
      "I0000 00:00:1736216865.457796 35797585 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.141689\n",
      "I0000 00:00:1736216865.505753 35797585 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.141834\n",
      "I0000 00:00:1736216865.552286 35797585 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.141743\n",
      "I0000 00:00:1736216865.599109 35797585 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.141533\n",
      "I0000 00:00:1736216865.645921 35797585 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.14147\n",
      "I0000 00:00:1736216865.691759 35797585 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.14161\n",
      "I0000 00:00:1736216865.737387 35797585 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.141593\n",
      "I0000 00:00:1736216865.782974 35797585 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.141534\n",
      "I0000 00:00:1736216865.829396 35797585 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.141581\n",
      "I0000 00:00:1736216865.874946 35797585 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.141619\n",
      "I0000 00:00:1736216865.920360 35797585 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.14159\n",
      "I0000 00:00:1736216865.965584 35797585 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.141562\n",
      "I0000 00:00:1736216866.011820 35797585 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.141483\n",
      "I0000 00:00:1736216866.057602 35797585 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.14116\n",
      "I0000 00:00:1736216866.104211 35797585 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.141048\n",
      "I0000 00:00:1736216866.151251 35797585 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.140981\n",
      "I0000 00:00:1736216866.197736 35797585 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.14098\n",
      "I0000 00:00:1736216866.244117 35797585 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.140898\n",
      "I0000 00:00:1736216866.290398 35797585 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.140734\n",
      "I0000 00:00:1736216866.336255 35797585 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.14063\n",
      "I0000 00:00:1736216866.382896 35797585 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.140623\n",
      "I0000 00:00:1736216866.428960 35797585 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.14061\n",
      "I0000 00:00:1736216866.475425 35797585 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.140853\n",
      "I0000 00:00:1736216866.521535 35797585 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.140944\n",
      "I0000 00:00:1736216866.568503 35797585 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.140806\n",
      "I0000 00:00:1736216866.614715 35797585 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.140737\n",
      "I0000 00:00:1736216866.660474 35797585 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.140781\n",
      "I0000 00:00:1736216866.706184 35797585 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.140703\n",
      "I0000 00:00:1736216866.752257 35797585 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.140669\n",
      "I0000 00:00:1736216866.797907 35797585 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.1407\n",
      "I0000 00:00:1736216866.839483 35797585 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.140689\n",
      "I0000 00:00:1736216866.839538 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.140689\n",
      "I0000 00:00:1736216866.858056 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:46.861117: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [3/20] Score: -0.140689 / -0.140689 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "I0000 00:00:1736216866.869280 35797601 random_forest.cc:811] Training of tree  1/100 (tree index:0) done rmse:0.237098\n",
      "I0000 00:00:1736216866.962871 35797601 random_forest.cc:811] Training of tree  11/100 (tree index:10) done rmse:0.164751\n",
      "I0000 00:00:1736216867.055240 35797601 random_forest.cc:811] Training of tree  21/100 (tree index:20) done rmse:0.151227\n",
      "I0000 00:00:1736216867.147283 35797601 random_forest.cc:811] Training of tree  31/100 (tree index:30) done rmse:0.145731\n",
      "I0000 00:00:1736216867.240874 35797601 random_forest.cc:811] Training of tree  41/100 (tree index:40) done rmse:0.142523\n",
      "I0000 00:00:1736216867.333733 35797601 random_forest.cc:811] Training of tree  51/100 (tree index:50) done rmse:0.140763\n",
      "I0000 00:00:1736216867.427818 35797601 random_forest.cc:811] Training of tree  61/100 (tree index:60) done rmse:0.140082\n",
      "I0000 00:00:1736216867.520405 35797601 random_forest.cc:811] Training of tree  71/100 (tree index:70) done rmse:0.139441\n",
      "I0000 00:00:1736216867.613483 35797601 random_forest.cc:811] Training of tree  81/100 (tree index:80) done rmse:0.139432\n",
      "I0000 00:00:1736216867.706128 35797601 random_forest.cc:811] Training of tree  91/100 (tree index:90) done rmse:0.139005\n",
      "I0000 00:00:1736216867.790202 35797601 random_forest.cc:811] Training of tree  100/100 (tree index:99) done rmse:0.138589\n",
      "I0000 00:00:1736216867.790256 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.138589\n",
      "I0000 00:00:1736216867.814020 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216867.820167 35797628 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.236338\n",
      "2025-01-06 21:27:47.821850: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [4/20] Score: -0.138589 / -0.138589 HParams: fields { name: \"num_trees\" value { integer: 100 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "I0000 00:00:1736216867.862562 35797628 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.166787\n",
      "I0000 00:00:1736216867.905174 35797628 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.153741\n",
      "I0000 00:00:1736216867.946866 35797628 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.149197\n",
      "I0000 00:00:1736216867.987893 35797628 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.146874\n",
      "I0000 00:00:1736216868.029310 35797628 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.145715\n",
      "I0000 00:00:1736216868.073921 35797628 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.145152\n",
      "I0000 00:00:1736216868.116861 35797628 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.144567\n",
      "I0000 00:00:1736216868.159002 35797628 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.144669\n",
      "I0000 00:00:1736216868.200900 35797628 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.144318\n",
      "I0000 00:00:1736216868.242203 35797628 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.143906\n",
      "I0000 00:00:1736216868.283570 35797628 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.143625\n",
      "I0000 00:00:1736216868.325881 35797628 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.143494\n",
      "I0000 00:00:1736216868.368902 35797628 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.143069\n",
      "I0000 00:00:1736216868.410616 35797628 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.142854\n",
      "I0000 00:00:1736216868.451542 35797628 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.142585\n",
      "I0000 00:00:1736216868.493608 35797628 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.142285\n",
      "I0000 00:00:1736216868.535314 35797628 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.142665\n",
      "I0000 00:00:1736216868.576610 35797628 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.142713\n",
      "I0000 00:00:1736216868.618129 35797628 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.142494\n",
      "I0000 00:00:1736216868.659079 35797628 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.142539\n",
      "I0000 00:00:1736216868.701174 35797628 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.14269\n",
      "I0000 00:00:1736216868.742230 35797628 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.142432\n",
      "I0000 00:00:1736216868.782922 35797628 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.14251\n",
      "I0000 00:00:1736216868.823589 35797628 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.142432\n",
      "I0000 00:00:1736216868.863614 35797628 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.142382\n",
      "I0000 00:00:1736216868.905474 35797628 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.142301\n",
      "I0000 00:00:1736216868.946178 35797628 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.142115\n",
      "I0000 00:00:1736216868.987021 35797628 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.142056\n",
      "I0000 00:00:1736216869.027085 35797628 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.14207\n",
      "I0000 00:00:1736216869.067539 35797628 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.14202\n",
      "I0000 00:00:1736216869.110536 35797628 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.142016\n",
      "I0000 00:00:1736216869.153423 35797628 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.141942\n",
      "I0000 00:00:1736216869.196719 35797628 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.141683\n",
      "I0000 00:00:1736216869.239514 35797628 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.141629\n",
      "I0000 00:00:1736216869.282708 35797628 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.141508\n",
      "I0000 00:00:1736216869.325352 35797628 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.141419\n",
      "I0000 00:00:1736216869.366341 35797628 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.141388\n",
      "I0000 00:00:1736216869.407531 35797628 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.141259\n",
      "I0000 00:00:1736216869.447772 35797628 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.141178\n",
      "I0000 00:00:1736216869.488431 35797628 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.141143\n",
      "I0000 00:00:1736216869.529347 35797628 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.140993\n",
      "I0000 00:00:1736216869.571855 35797628 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.141097\n",
      "I0000 00:00:1736216869.613585 35797628 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.141112\n",
      "I0000 00:00:1736216869.654926 35797628 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.141172\n",
      "I0000 00:00:1736216869.695805 35797628 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.141144\n",
      "I0000 00:00:1736216869.737669 35797628 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.141143\n",
      "I0000 00:00:1736216869.779697 35797628 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.141127\n",
      "I0000 00:00:1736216869.821744 35797628 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.141098\n",
      "I0000 00:00:1736216869.862295 35797628 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.14115\n",
      "I0000 00:00:1736216869.899449 35797628 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.141244\n",
      "I0000 00:00:1736216869.899498 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.141244\n",
      "2025-01-06 21:27:49.915598: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [5/20] Score: -0.141244 / -0.138589 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "I0000 00:00:1736216869.915934 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216869.922751 35797720 random_forest.cc:811] Training of tree  1/200 (tree index:0) done rmse:0.205591\n",
      "I0000 00:00:1736216869.969362 35797720 random_forest.cc:811] Training of tree  11/200 (tree index:10) done rmse:0.164376\n",
      "I0000 00:00:1736216870.015138 35797720 random_forest.cc:811] Training of tree  21/200 (tree index:20) done rmse:0.153089\n",
      "I0000 00:00:1736216870.060835 35797720 random_forest.cc:811] Training of tree  31/200 (tree index:30) done rmse:0.146778\n",
      "I0000 00:00:1736216870.106839 35797720 random_forest.cc:811] Training of tree  41/200 (tree index:40) done rmse:0.14597\n",
      "I0000 00:00:1736216870.153467 35797720 random_forest.cc:811] Training of tree  51/200 (tree index:50) done rmse:0.144875\n",
      "I0000 00:00:1736216870.198817 35797720 random_forest.cc:811] Training of tree  61/200 (tree index:60) done rmse:0.144789\n",
      "I0000 00:00:1736216870.244665 35797720 random_forest.cc:811] Training of tree  71/200 (tree index:70) done rmse:0.144079\n",
      "I0000 00:00:1736216870.290621 35797720 random_forest.cc:811] Training of tree  81/200 (tree index:80) done rmse:0.144381\n",
      "I0000 00:00:1736216870.337576 35797720 random_forest.cc:811] Training of tree  91/200 (tree index:90) done rmse:0.144205\n",
      "I0000 00:00:1736216870.384186 35797720 random_forest.cc:811] Training of tree  101/200 (tree index:100) done rmse:0.143531\n",
      "I0000 00:00:1736216870.430400 35797720 random_forest.cc:811] Training of tree  111/200 (tree index:110) done rmse:0.142995\n",
      "I0000 00:00:1736216870.476946 35797720 random_forest.cc:811] Training of tree  121/200 (tree index:120) done rmse:0.142692\n",
      "I0000 00:00:1736216870.522921 35797720 random_forest.cc:811] Training of tree  131/200 (tree index:130) done rmse:0.142352\n",
      "I0000 00:00:1736216870.570142 35797720 random_forest.cc:811] Training of tree  141/200 (tree index:140) done rmse:0.142192\n",
      "I0000 00:00:1736216870.617647 35797720 random_forest.cc:811] Training of tree  151/200 (tree index:150) done rmse:0.141775\n",
      "I0000 00:00:1736216870.663974 35797720 random_forest.cc:811] Training of tree  161/200 (tree index:160) done rmse:0.141641\n",
      "I0000 00:00:1736216870.710896 35797720 random_forest.cc:811] Training of tree  171/200 (tree index:170) done rmse:0.141786\n",
      "I0000 00:00:1736216870.758168 35797720 random_forest.cc:811] Training of tree  181/200 (tree index:180) done rmse:0.141871\n",
      "I0000 00:00:1736216870.805014 35797720 random_forest.cc:811] Training of tree  191/200 (tree index:190) done rmse:0.141598\n",
      "I0000 00:00:1736216870.851886 35797720 random_forest.cc:811] Training of tree  200/200 (tree index:199) done rmse:0.141716\n",
      "I0000 00:00:1736216870.851960 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.141716\n",
      "2025-01-06 21:27:50.859861: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [6/20] Score: -0.141716 / -0.138589 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"max_depth\" value { integer: -1 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "I0000 00:00:1736216870.860229 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216870.868155 35797726 random_forest.cc:811] Training of tree  1/200 (tree index:0) done rmse:0.202854\n",
      "I0000 00:00:1736216870.928235 35797726 random_forest.cc:811] Training of tree  11/200 (tree index:10) done rmse:0.168443\n",
      "I0000 00:00:1736216870.988741 35797726 random_forest.cc:811] Training of tree  21/200 (tree index:20) done rmse:0.152315\n",
      "I0000 00:00:1736216871.049791 35797726 random_forest.cc:811] Training of tree  31/200 (tree index:30) done rmse:0.147728\n",
      "I0000 00:00:1736216871.110891 35797726 random_forest.cc:811] Training of tree  41/200 (tree index:40) done rmse:0.144086\n",
      "I0000 00:00:1736216871.172289 35797726 random_forest.cc:811] Training of tree  51/200 (tree index:50) done rmse:0.143011\n",
      "I0000 00:00:1736216871.232811 35797726 random_forest.cc:811] Training of tree  61/200 (tree index:60) done rmse:0.142305\n",
      "I0000 00:00:1736216871.292900 35797726 random_forest.cc:811] Training of tree  71/200 (tree index:70) done rmse:0.141454\n",
      "I0000 00:00:1736216871.354295 35797726 random_forest.cc:811] Training of tree  81/200 (tree index:80) done rmse:0.141248\n",
      "I0000 00:00:1736216871.414731 35797726 random_forest.cc:811] Training of tree  91/200 (tree index:90) done rmse:0.140506\n",
      "I0000 00:00:1736216871.474564 35797726 random_forest.cc:811] Training of tree  101/200 (tree index:100) done rmse:0.14066\n",
      "I0000 00:00:1736216871.535605 35797726 random_forest.cc:811] Training of tree  111/200 (tree index:110) done rmse:0.140093\n",
      "I0000 00:00:1736216871.597006 35797726 random_forest.cc:811] Training of tree  121/200 (tree index:120) done rmse:0.139605\n",
      "I0000 00:00:1736216871.657384 35797726 random_forest.cc:811] Training of tree  131/200 (tree index:130) done rmse:0.139147\n",
      "I0000 00:00:1736216871.717290 35797726 random_forest.cc:811] Training of tree  141/200 (tree index:140) done rmse:0.138538\n",
      "I0000 00:00:1736216871.778338 35797726 random_forest.cc:811] Training of tree  151/200 (tree index:150) done rmse:0.138212\n",
      "I0000 00:00:1736216871.837968 35797726 random_forest.cc:811] Training of tree  161/200 (tree index:160) done rmse:0.137746\n",
      "I0000 00:00:1736216871.899022 35797726 random_forest.cc:811] Training of tree  171/200 (tree index:170) done rmse:0.137806\n",
      "I0000 00:00:1736216871.959682 35797726 random_forest.cc:811] Training of tree  181/200 (tree index:180) done rmse:0.13779\n",
      "I0000 00:00:1736216872.020942 35797726 random_forest.cc:811] Training of tree  191/200 (tree index:190) done rmse:0.137515\n",
      "I0000 00:00:1736216872.077109 35797726 random_forest.cc:811] Training of tree  200/200 (tree index:199) done rmse:0.137333\n",
      "I0000 00:00:1736216872.077167 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.137333\n",
      "I0000 00:00:1736216872.094737 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:52.102577: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [7/20] Score: -0.137333 / -0.137333 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "I0000 00:00:1736216872.106455 35797737 random_forest.cc:811] Training of tree  1/200 (tree index:0) done rmse:0.237098\n",
      "I0000 00:00:1736216872.199248 35797737 random_forest.cc:811] Training of tree  11/200 (tree index:10) done rmse:0.164751\n",
      "I0000 00:00:1736216872.291796 35797737 random_forest.cc:811] Training of tree  21/200 (tree index:20) done rmse:0.151227\n",
      "I0000 00:00:1736216872.385296 35797737 random_forest.cc:811] Training of tree  31/200 (tree index:30) done rmse:0.145731\n",
      "I0000 00:00:1736216872.478047 35797737 random_forest.cc:811] Training of tree  41/200 (tree index:40) done rmse:0.142523\n",
      "I0000 00:00:1736216872.572430 35797737 random_forest.cc:811] Training of tree  51/200 (tree index:50) done rmse:0.140763\n",
      "I0000 00:00:1736216872.665552 35797737 random_forest.cc:811] Training of tree  61/200 (tree index:60) done rmse:0.140082\n",
      "I0000 00:00:1736216872.757951 35797737 random_forest.cc:811] Training of tree  71/200 (tree index:70) done rmse:0.139441\n",
      "I0000 00:00:1736216872.850210 35797737 random_forest.cc:811] Training of tree  81/200 (tree index:80) done rmse:0.139432\n",
      "I0000 00:00:1736216872.942266 35797737 random_forest.cc:811] Training of tree  91/200 (tree index:90) done rmse:0.139005\n",
      "I0000 00:00:1736216873.036121 35797737 random_forest.cc:811] Training of tree  101/200 (tree index:100) done rmse:0.138464\n",
      "I0000 00:00:1736216873.129751 35797737 random_forest.cc:811] Training of tree  111/200 (tree index:110) done rmse:0.13818\n",
      "I0000 00:00:1736216873.222528 35797737 random_forest.cc:811] Training of tree  121/200 (tree index:120) done rmse:0.138369\n",
      "I0000 00:00:1736216873.315132 35797737 random_forest.cc:811] Training of tree  131/200 (tree index:130) done rmse:0.137788\n",
      "I0000 00:00:1736216873.408285 35797737 random_forest.cc:811] Training of tree  141/200 (tree index:140) done rmse:0.137706\n",
      "I0000 00:00:1736216873.501723 35797737 random_forest.cc:811] Training of tree  151/200 (tree index:150) done rmse:0.137348\n",
      "I0000 00:00:1736216873.594750 35797737 random_forest.cc:811] Training of tree  161/200 (tree index:160) done rmse:0.137273\n",
      "I0000 00:00:1736216873.686393 35797737 random_forest.cc:811] Training of tree  171/200 (tree index:170) done rmse:0.137551\n",
      "I0000 00:00:1736216873.780361 35797737 random_forest.cc:811] Training of tree  181/200 (tree index:180) done rmse:0.137434\n",
      "I0000 00:00:1736216873.873635 35797737 random_forest.cc:811] Training of tree  191/200 (tree index:190) done rmse:0.137046\n",
      "I0000 00:00:1736216873.964266 35797737 random_forest.cc:811] Training of tree  200/200 (tree index:199) done rmse:0.136888\n",
      "I0000 00:00:1736216873.964326 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.136888\n",
      "I0000 00:00:1736216874.012485 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "2025-01-06 21:27:54.018748: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [8/20] Score: -0.136888 / -0.136888 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"max_depth\" value { integer: -1 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "I0000 00:00:1736216874.019243 35797761 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.205591\n",
      "I0000 00:00:1736216874.065161 35797761 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.164376\n",
      "I0000 00:00:1736216874.110967 35797761 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.153089\n",
      "I0000 00:00:1736216874.156848 35797761 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.146778\n",
      "I0000 00:00:1736216874.204253 35797761 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.14597\n",
      "I0000 00:00:1736216874.251151 35797761 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.144875\n",
      "I0000 00:00:1736216874.297150 35797761 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.144789\n",
      "I0000 00:00:1736216874.343335 35797761 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.144079\n",
      "I0000 00:00:1736216874.388997 35797761 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.144381\n",
      "I0000 00:00:1736216874.434991 35797761 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.144205\n",
      "I0000 00:00:1736216874.481868 35797761 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.143531\n",
      "I0000 00:00:1736216874.528512 35797761 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.142995\n",
      "I0000 00:00:1736216874.574877 35797761 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.142692\n",
      "I0000 00:00:1736216874.620688 35797761 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.142352\n",
      "I0000 00:00:1736216874.667267 35797761 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.142192\n",
      "I0000 00:00:1736216874.714647 35797761 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.141775\n",
      "I0000 00:00:1736216874.760609 35797761 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.141641\n",
      "I0000 00:00:1736216874.806568 35797761 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.141786\n",
      "I0000 00:00:1736216874.853027 35797761 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.141871\n",
      "I0000 00:00:1736216874.899949 35797761 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.141598\n",
      "I0000 00:00:1736216874.947702 35797761 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.141689\n",
      "I0000 00:00:1736216874.994441 35797761 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.141834\n",
      "I0000 00:00:1736216875.039950 35797761 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.141743\n",
      "I0000 00:00:1736216875.086413 35797761 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.141533\n",
      "I0000 00:00:1736216875.132775 35797761 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.14147\n",
      "I0000 00:00:1736216875.179468 35797761 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.14161\n",
      "I0000 00:00:1736216875.226695 35797761 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.141593\n",
      "I0000 00:00:1736216875.273300 35797761 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.141534\n",
      "I0000 00:00:1736216875.320376 35797761 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.141581\n",
      "I0000 00:00:1736216875.366922 35797761 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.141619\n",
      "I0000 00:00:1736216875.413138 35797761 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.14159\n",
      "I0000 00:00:1736216875.458980 35797761 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.141562\n",
      "I0000 00:00:1736216875.504762 35797761 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.141483\n",
      "I0000 00:00:1736216875.550705 35797761 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.14116\n",
      "I0000 00:00:1736216875.596871 35797761 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.141048\n",
      "I0000 00:00:1736216875.644462 35797761 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.140981\n",
      "I0000 00:00:1736216875.691111 35797761 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.14098\n",
      "I0000 00:00:1736216875.736849 35797761 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.140898\n",
      "I0000 00:00:1736216875.782199 35797761 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.140734\n",
      "I0000 00:00:1736216875.828601 35797761 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.14063\n",
      "I0000 00:00:1736216875.875397 35797761 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.140623\n",
      "I0000 00:00:1736216875.920740 35797761 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.14061\n",
      "I0000 00:00:1736216875.966198 35797761 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.140853\n",
      "I0000 00:00:1736216876.012025 35797761 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.140944\n",
      "I0000 00:00:1736216876.058951 35797761 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.140806\n",
      "I0000 00:00:1736216876.105653 35797761 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.140737\n",
      "I0000 00:00:1736216876.152339 35797761 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.140781\n",
      "I0000 00:00:1736216876.198696 35797761 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.140703\n",
      "I0000 00:00:1736216876.245282 35797761 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.140669\n",
      "I0000 00:00:1736216876.292476 35797761 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.1407\n",
      "I0000 00:00:1736216876.334704 35797761 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.140689\n",
      "I0000 00:00:1736216876.334768 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.140689\n",
      "2025-01-06 21:27:56.353422: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [9/20] Score: -0.140689 / -0.136888 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: -1 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "I0000 00:00:1736216876.353767 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216876.362041 35797822 random_forest.cc:811] Training of tree  1/100 (tree index:0) done rmse:0.202854\n",
      "I0000 00:00:1736216876.423624 35797822 random_forest.cc:811] Training of tree  11/100 (tree index:10) done rmse:0.168443\n",
      "I0000 00:00:1736216876.484358 35797822 random_forest.cc:811] Training of tree  21/100 (tree index:20) done rmse:0.152315\n",
      "I0000 00:00:1736216876.550248 35797822 random_forest.cc:811] Training of tree  31/100 (tree index:30) done rmse:0.147728\n",
      "I0000 00:00:1736216876.612735 35797822 random_forest.cc:811] Training of tree  41/100 (tree index:40) done rmse:0.144086\n",
      "I0000 00:00:1736216876.673461 35797822 random_forest.cc:811] Training of tree  51/100 (tree index:50) done rmse:0.143011\n",
      "I0000 00:00:1736216876.733654 35797822 random_forest.cc:811] Training of tree  61/100 (tree index:60) done rmse:0.142305\n",
      "I0000 00:00:1736216876.794088 35797822 random_forest.cc:811] Training of tree  71/100 (tree index:70) done rmse:0.141454\n",
      "I0000 00:00:1736216876.854630 35797822 random_forest.cc:811] Training of tree  81/100 (tree index:80) done rmse:0.141248\n",
      "I0000 00:00:1736216876.914067 35797822 random_forest.cc:811] Training of tree  91/100 (tree index:90) done rmse:0.140506\n",
      "I0000 00:00:1736216876.968169 35797822 random_forest.cc:811] Training of tree  100/100 (tree index:99) done rmse:0.140873\n",
      "I0000 00:00:1736216876.968224 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.140873\n",
      "2025-01-06 21:27:56.976333: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [10/20] Score: -0.140873 / -0.136888 HParams: fields { name: \"num_trees\" value { integer: 100 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "I0000 00:00:1736216876.976660 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216876.982647 35797829 random_forest.cc:811] Training of tree  1/200 (tree index:0) done rmse:0.236338\n",
      "I0000 00:00:1736216877.024114 35797829 random_forest.cc:811] Training of tree  11/200 (tree index:10) done rmse:0.166787\n",
      "I0000 00:00:1736216877.066431 35797829 random_forest.cc:811] Training of tree  21/200 (tree index:20) done rmse:0.153741\n",
      "I0000 00:00:1736216877.108503 35797829 random_forest.cc:811] Training of tree  31/200 (tree index:30) done rmse:0.149197\n",
      "I0000 00:00:1736216877.149938 35797829 random_forest.cc:811] Training of tree  41/200 (tree index:40) done rmse:0.146874\n",
      "I0000 00:00:1736216877.190692 35797829 random_forest.cc:811] Training of tree  51/200 (tree index:50) done rmse:0.145715\n",
      "I0000 00:00:1736216877.231748 35797829 random_forest.cc:811] Training of tree  61/200 (tree index:60) done rmse:0.145152\n",
      "I0000 00:00:1736216877.273403 35797829 random_forest.cc:811] Training of tree  71/200 (tree index:70) done rmse:0.144567\n",
      "I0000 00:00:1736216877.327683 35797829 random_forest.cc:811] Training of tree  81/200 (tree index:80) done rmse:0.144669\n",
      "I0000 00:00:1736216877.369823 35797829 random_forest.cc:811] Training of tree  91/200 (tree index:90) done rmse:0.144318\n",
      "I0000 00:00:1736216877.411510 35797829 random_forest.cc:811] Training of tree  101/200 (tree index:100) done rmse:0.143906\n",
      "I0000 00:00:1736216877.452808 35797829 random_forest.cc:811] Training of tree  111/200 (tree index:110) done rmse:0.143625\n",
      "I0000 00:00:1736216877.493901 35797829 random_forest.cc:811] Training of tree  121/200 (tree index:120) done rmse:0.143494\n",
      "I0000 00:00:1736216877.535336 35797829 random_forest.cc:811] Training of tree  131/200 (tree index:130) done rmse:0.143069\n",
      "I0000 00:00:1736216877.576887 35797829 random_forest.cc:811] Training of tree  141/200 (tree index:140) done rmse:0.142854\n",
      "I0000 00:00:1736216877.617588 35797829 random_forest.cc:811] Training of tree  151/200 (tree index:150) done rmse:0.142585\n",
      "I0000 00:00:1736216877.658494 35797829 random_forest.cc:811] Training of tree  161/200 (tree index:160) done rmse:0.142285\n",
      "I0000 00:00:1736216877.700543 35797829 random_forest.cc:811] Training of tree  171/200 (tree index:170) done rmse:0.142665\n",
      "I0000 00:00:1736216877.741353 35797829 random_forest.cc:811] Training of tree  181/200 (tree index:180) done rmse:0.142713\n",
      "I0000 00:00:1736216877.781420 35797829 random_forest.cc:811] Training of tree  191/200 (tree index:190) done rmse:0.142494\n",
      "I0000 00:00:1736216877.818838 35797829 random_forest.cc:811] Training of tree  200/200 (tree index:199) done rmse:0.142579\n",
      "I0000 00:00:1736216877.818894 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.142579\n",
      "2025-01-06 21:27:57.825339: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [11/20] Score: -0.142579 / -0.136888 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 10 } }\n",
      "I0000 00:00:1736216877.825679 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216877.837084 35797842 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.237098\n",
      "I0000 00:00:1736216877.930855 35797842 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.164751\n",
      "I0000 00:00:1736216878.023788 35797842 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.151227\n",
      "I0000 00:00:1736216878.119302 35797842 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.145731\n",
      "I0000 00:00:1736216878.214588 35797842 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.142523\n",
      "I0000 00:00:1736216878.309267 35797842 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.140763\n",
      "I0000 00:00:1736216878.401535 35797842 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.140082\n",
      "I0000 00:00:1736216878.495376 35797842 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.139441\n",
      "I0000 00:00:1736216878.588251 35797842 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.139432\n",
      "I0000 00:00:1736216878.682067 35797842 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.139005\n",
      "I0000 00:00:1736216878.777680 35797842 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.138464\n",
      "I0000 00:00:1736216878.871633 35797842 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.13818\n",
      "I0000 00:00:1736216878.964015 35797842 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.138369\n",
      "I0000 00:00:1736216879.055357 35797842 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.137788\n",
      "I0000 00:00:1736216879.146657 35797842 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.137706\n",
      "I0000 00:00:1736216879.239822 35797842 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.137348\n",
      "I0000 00:00:1736216879.333128 35797842 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.137273\n",
      "I0000 00:00:1736216879.424546 35797842 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.137551\n",
      "I0000 00:00:1736216879.517726 35797842 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.137434\n",
      "I0000 00:00:1736216879.611657 35797842 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.137046\n",
      "I0000 00:00:1736216879.704064 35797842 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.136905\n",
      "I0000 00:00:1736216879.796324 35797842 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.136918\n",
      "I0000 00:00:1736216879.888730 35797842 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.136892\n",
      "I0000 00:00:1736216879.980162 35797842 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.13665\n",
      "I0000 00:00:1736216880.072240 35797842 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.136462\n",
      "I0000 00:00:1736216880.164275 35797842 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.13666\n",
      "I0000 00:00:1736216880.255304 35797842 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.136485\n",
      "I0000 00:00:1736216880.346902 35797842 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.136472\n",
      "I0000 00:00:1736216880.437821 35797842 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.136398\n",
      "I0000 00:00:1736216880.532152 35797842 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.136288\n",
      "I0000 00:00:1736216880.628976 35797842 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.136434\n",
      "I0000 00:00:1736216880.722688 35797842 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.136454\n",
      "I0000 00:00:1736216880.814800 35797842 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.136363\n",
      "I0000 00:00:1736216880.905394 35797842 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.136143\n",
      "I0000 00:00:1736216880.997226 35797842 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.136292\n",
      "I0000 00:00:1736216881.089816 35797842 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.136282\n",
      "I0000 00:00:1736216881.181726 35797842 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.136268\n",
      "I0000 00:00:1736216881.273077 35797842 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.136394\n",
      "I0000 00:00:1736216881.365814 35797842 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.136362\n",
      "I0000 00:00:1736216881.457814 35797842 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.136388\n",
      "I0000 00:00:1736216881.549314 35797842 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.136114\n",
      "I0000 00:00:1736216881.640231 35797842 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.135983\n",
      "I0000 00:00:1736216881.730970 35797842 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.135966\n",
      "I0000 00:00:1736216881.820964 35797842 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.135944\n",
      "I0000 00:00:1736216881.912484 35797842 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.135909\n",
      "I0000 00:00:1736216882.004446 35797842 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.136028\n",
      "I0000 00:00:1736216882.095204 35797842 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.135966\n",
      "I0000 00:00:1736216882.185564 35797842 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.135929\n",
      "I0000 00:00:1736216882.311854 35797842 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.135933\n",
      "I0000 00:00:1736216882.406859 35797842 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.135803\n",
      "I0000 00:00:1736216882.491094 35797842 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.135769\n",
      "I0000 00:00:1736216882.491154 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.135769\n",
      "I0000 00:00:1736216882.610773 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216882.617375 35797914 random_forest.cc:811] Training of tree  1/200 (tree index:0) done rmse:0.243654\n",
      "2025-01-06 21:28:02.626777: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [12/20] Score: -0.135769 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "I0000 00:00:1736216882.663560 35797914 random_forest.cc:811] Training of tree  11/200 (tree index:10) done rmse:0.169583\n",
      "I0000 00:00:1736216882.708174 35797914 random_forest.cc:811] Training of tree  21/200 (tree index:20) done rmse:0.151559\n",
      "I0000 00:00:1736216882.753589 35797914 random_forest.cc:811] Training of tree  31/200 (tree index:30) done rmse:0.146799\n",
      "I0000 00:00:1736216882.799749 35797914 random_forest.cc:811] Training of tree  41/200 (tree index:40) done rmse:0.145226\n",
      "I0000 00:00:1736216882.842769 35797914 random_forest.cc:811] Training of tree  51/200 (tree index:50) done rmse:0.143948\n",
      "I0000 00:00:1736216882.886640 35797914 random_forest.cc:811] Training of tree  61/200 (tree index:60) done rmse:0.143648\n",
      "I0000 00:00:1736216882.935456 35797914 random_forest.cc:811] Training of tree  71/200 (tree index:70) done rmse:0.143092\n",
      "I0000 00:00:1736216882.980324 35797914 random_forest.cc:811] Training of tree  81/200 (tree index:80) done rmse:0.142386\n",
      "I0000 00:00:1736216883.026139 35797914 random_forest.cc:811] Training of tree  91/200 (tree index:90) done rmse:0.142159\n",
      "I0000 00:00:1736216883.070510 35797914 random_forest.cc:811] Training of tree  101/200 (tree index:100) done rmse:0.141564\n",
      "I0000 00:00:1736216883.120330 35797914 random_forest.cc:811] Training of tree  111/200 (tree index:110) done rmse:0.141439\n",
      "I0000 00:00:1736216883.171233 35797914 random_forest.cc:811] Training of tree  121/200 (tree index:120) done rmse:0.141118\n",
      "I0000 00:00:1736216883.220092 35797914 random_forest.cc:811] Training of tree  131/200 (tree index:130) done rmse:0.141301\n",
      "I0000 00:00:1736216883.282815 35797914 random_forest.cc:811] Training of tree  141/200 (tree index:140) done rmse:0.140865\n",
      "I0000 00:00:1736216883.328634 35797914 random_forest.cc:811] Training of tree  151/200 (tree index:150) done rmse:0.140624\n",
      "I0000 00:00:1736216883.372767 35797914 random_forest.cc:811] Training of tree  161/200 (tree index:160) done rmse:0.139869\n",
      "I0000 00:00:1736216883.417327 35797914 random_forest.cc:811] Training of tree  171/200 (tree index:170) done rmse:0.139589\n",
      "I0000 00:00:1736216883.463876 35797914 random_forest.cc:811] Training of tree  181/200 (tree index:180) done rmse:0.139628\n",
      "I0000 00:00:1736216883.507264 35797914 random_forest.cc:811] Training of tree  191/200 (tree index:190) done rmse:0.139442\n",
      "I0000 00:00:1736216883.547199 35797914 random_forest.cc:811] Training of tree  200/200 (tree index:199) done rmse:0.139462\n",
      "I0000 00:00:1736216883.547253 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.139462\n",
      "2025-01-06 21:28:03.558060: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [13/20] Score: -0.139462 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "I0000 00:00:1736216883.558437 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216883.569531 35798002 random_forest.cc:811] Training of tree  1/100 (tree index:0) done rmse:0.237098\n",
      "I0000 00:00:1736216883.700844 35798002 random_forest.cc:811] Training of tree  11/100 (tree index:10) done rmse:0.164751\n",
      "I0000 00:00:1736216883.792515 35798002 random_forest.cc:811] Training of tree  21/100 (tree index:20) done rmse:0.151227\n",
      "I0000 00:00:1736216883.885695 35798002 random_forest.cc:811] Training of tree  31/100 (tree index:30) done rmse:0.145731\n",
      "I0000 00:00:1736216883.978581 35798002 random_forest.cc:811] Training of tree  41/100 (tree index:40) done rmse:0.142523\n",
      "I0000 00:00:1736216884.073734 35798002 random_forest.cc:811] Training of tree  51/100 (tree index:50) done rmse:0.140763\n",
      "I0000 00:00:1736216884.169835 35798002 random_forest.cc:811] Training of tree  61/100 (tree index:60) done rmse:0.140082\n",
      "I0000 00:00:1736216884.260997 35798002 random_forest.cc:811] Training of tree  71/100 (tree index:70) done rmse:0.139441\n",
      "I0000 00:00:1736216884.352247 35798002 random_forest.cc:811] Training of tree  81/100 (tree index:80) done rmse:0.139432\n",
      "I0000 00:00:1736216884.445228 35798002 random_forest.cc:811] Training of tree  91/100 (tree index:90) done rmse:0.139005\n",
      "I0000 00:00:1736216884.528095 35798002 random_forest.cc:811] Training of tree  100/100 (tree index:99) done rmse:0.138589\n",
      "I0000 00:00:1736216884.528149 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.138589\n",
      "2025-01-06 21:28:04.550737: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [14/20] Score: -0.138589 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 100 } } fields { name: \"max_depth\" value { integer: -1 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "I0000 00:00:1736216884.551076 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216884.559283 35798039 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.202854\n",
      "I0000 00:00:1736216884.618395 35798039 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.168443\n",
      "I0000 00:00:1736216884.677958 35798039 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.152315\n",
      "I0000 00:00:1736216884.738116 35798039 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.147728\n",
      "I0000 00:00:1736216884.798925 35798039 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.144086\n",
      "I0000 00:00:1736216884.859901 35798039 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.143011\n",
      "I0000 00:00:1736216884.920394 35798039 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.142305\n",
      "I0000 00:00:1736216884.979596 35798039 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.141454\n",
      "I0000 00:00:1736216885.038764 35798039 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.141248\n",
      "I0000 00:00:1736216885.097567 35798039 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.140506\n",
      "I0000 00:00:1736216885.156966 35798039 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.14066\n",
      "I0000 00:00:1736216885.216456 35798039 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.140093\n",
      "I0000 00:00:1736216885.276051 35798039 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.139605\n",
      "I0000 00:00:1736216885.335552 35798039 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.139147\n",
      "I0000 00:00:1736216885.394699 35798039 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.138538\n",
      "I0000 00:00:1736216885.453782 35798039 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.138212\n",
      "I0000 00:00:1736216885.512929 35798039 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.137746\n",
      "I0000 00:00:1736216885.572660 35798039 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.137806\n",
      "I0000 00:00:1736216885.632044 35798039 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.13779\n",
      "I0000 00:00:1736216885.691821 35798039 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.137515\n",
      "I0000 00:00:1736216885.752035 35798039 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.137309\n",
      "I0000 00:00:1736216885.812221 35798039 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.137529\n",
      "I0000 00:00:1736216885.872732 35798039 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.137556\n",
      "I0000 00:00:1736216885.932301 35798039 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.137388\n",
      "I0000 00:00:1736216885.992149 35798039 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.137481\n",
      "I0000 00:00:1736216886.052594 35798039 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.137284\n",
      "I0000 00:00:1736216886.113393 35798039 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.137261\n",
      "I0000 00:00:1736216886.173165 35798039 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.137169\n",
      "I0000 00:00:1736216886.231857 35798039 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.137336\n",
      "I0000 00:00:1736216886.290713 35798039 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.137352\n",
      "I0000 00:00:1736216886.349440 35798039 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.13755\n",
      "I0000 00:00:1736216886.408406 35798039 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.137672\n",
      "I0000 00:00:1736216886.468210 35798039 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.137701\n",
      "I0000 00:00:1736216886.527641 35798039 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.137578\n",
      "I0000 00:00:1736216886.587510 35798039 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.137509\n",
      "I0000 00:00:1736216886.647628 35798039 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.137441\n",
      "I0000 00:00:1736216886.707921 35798039 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.13738\n",
      "I0000 00:00:1736216886.767671 35798039 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.137455\n",
      "I0000 00:00:1736216886.827909 35798039 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.137398\n",
      "I0000 00:00:1736216886.887602 35798039 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.137409\n",
      "I0000 00:00:1736216886.947499 35798039 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.137399\n",
      "I0000 00:00:1736216887.007418 35798039 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.137305\n",
      "I0000 00:00:1736216887.071069 35798039 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.137379\n",
      "I0000 00:00:1736216887.132129 35798039 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.137524\n",
      "I0000 00:00:1736216887.193520 35798039 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.13745\n",
      "I0000 00:00:1736216887.255336 35798039 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.137239\n",
      "I0000 00:00:1736216887.317501 35798039 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.137209\n",
      "I0000 00:00:1736216887.378649 35798039 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.137138\n",
      "I0000 00:00:1736216887.439646 35798039 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.137189\n",
      "I0000 00:00:1736216887.499649 35798039 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.137254\n",
      "I0000 00:00:1736216887.553562 35798039 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.137149\n",
      "I0000 00:00:1736216887.553615 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.137149\n",
      "2025-01-06 21:28:07.596600: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [15/20] Score: -0.137149 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "I0000 00:00:1736216887.596966 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216887.605290 35798092 random_forest.cc:811] Training of tree  1/200 (tree index:0) done rmse:0.202854\n",
      "I0000 00:00:1736216887.667611 35798092 random_forest.cc:811] Training of tree  11/200 (tree index:10) done rmse:0.168443\n",
      "I0000 00:00:1736216887.729779 35798092 random_forest.cc:811] Training of tree  21/200 (tree index:20) done rmse:0.152315\n",
      "I0000 00:00:1736216887.790622 35798092 random_forest.cc:811] Training of tree  31/200 (tree index:30) done rmse:0.147728\n",
      "I0000 00:00:1736216887.851438 35798092 random_forest.cc:811] Training of tree  41/200 (tree index:40) done rmse:0.144086\n",
      "I0000 00:00:1736216887.912643 35798092 random_forest.cc:811] Training of tree  51/200 (tree index:50) done rmse:0.143011\n",
      "I0000 00:00:1736216887.973809 35798092 random_forest.cc:811] Training of tree  61/200 (tree index:60) done rmse:0.142305\n",
      "I0000 00:00:1736216888.033791 35798092 random_forest.cc:811] Training of tree  71/200 (tree index:70) done rmse:0.141454\n",
      "I0000 00:00:1736216888.093067 35798092 random_forest.cc:811] Training of tree  81/200 (tree index:80) done rmse:0.141248\n",
      "I0000 00:00:1736216888.152528 35798092 random_forest.cc:811] Training of tree  91/200 (tree index:90) done rmse:0.140506\n",
      "I0000 00:00:1736216888.212564 35798092 random_forest.cc:811] Training of tree  101/200 (tree index:100) done rmse:0.14066\n",
      "I0000 00:00:1736216888.280036 35798092 random_forest.cc:811] Training of tree  111/200 (tree index:110) done rmse:0.140093\n",
      "I0000 00:00:1736216888.341742 35798092 random_forest.cc:811] Training of tree  121/200 (tree index:120) done rmse:0.139605\n",
      "I0000 00:00:1736216888.404433 35798092 random_forest.cc:811] Training of tree  131/200 (tree index:130) done rmse:0.139147\n",
      "I0000 00:00:1736216888.471502 35798092 random_forest.cc:811] Training of tree  141/200 (tree index:140) done rmse:0.138538\n",
      "I0000 00:00:1736216888.531980 35798092 random_forest.cc:811] Training of tree  151/200 (tree index:150) done rmse:0.138212\n",
      "I0000 00:00:1736216888.591261 35798092 random_forest.cc:811] Training of tree  161/200 (tree index:160) done rmse:0.137746\n",
      "I0000 00:00:1736216888.654362 35798092 random_forest.cc:811] Training of tree  171/200 (tree index:170) done rmse:0.137806\n",
      "I0000 00:00:1736216888.715311 35798092 random_forest.cc:811] Training of tree  181/200 (tree index:180) done rmse:0.13779\n",
      "I0000 00:00:1736216888.775293 35798092 random_forest.cc:811] Training of tree  191/200 (tree index:190) done rmse:0.137515\n",
      "I0000 00:00:1736216888.829865 35798092 random_forest.cc:811] Training of tree  200/200 (tree index:199) done rmse:0.137333\n",
      "I0000 00:00:1736216888.829921 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.137333\n",
      "2025-01-06 21:28:08.846770: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [16/20] Score: -0.137333 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"max_depth\" value { integer: -1 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "I0000 00:00:1736216888.847094 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216888.858765 35798153 random_forest.cc:811] Training of tree  1/200 (tree index:0) done rmse:0.237098\n",
      "I0000 00:00:1736216888.953423 35798153 random_forest.cc:811] Training of tree  11/200 (tree index:10) done rmse:0.164751\n",
      "I0000 00:00:1736216889.046898 35798153 random_forest.cc:811] Training of tree  21/200 (tree index:20) done rmse:0.151227\n",
      "I0000 00:00:1736216889.141005 35798153 random_forest.cc:811] Training of tree  31/200 (tree index:30) done rmse:0.145731\n",
      "I0000 00:00:1736216889.235267 35798153 random_forest.cc:811] Training of tree  41/200 (tree index:40) done rmse:0.142523\n",
      "I0000 00:00:1736216889.331516 35798153 random_forest.cc:811] Training of tree  51/200 (tree index:50) done rmse:0.140763\n",
      "I0000 00:00:1736216889.425423 35798153 random_forest.cc:811] Training of tree  61/200 (tree index:60) done rmse:0.140082\n",
      "I0000 00:00:1736216889.518231 35798153 random_forest.cc:811] Training of tree  71/200 (tree index:70) done rmse:0.139441\n",
      "I0000 00:00:1736216889.612793 35798153 random_forest.cc:811] Training of tree  81/200 (tree index:80) done rmse:0.139432\n",
      "I0000 00:00:1736216889.712663 35798153 random_forest.cc:811] Training of tree  91/200 (tree index:90) done rmse:0.139005\n",
      "I0000 00:00:1736216889.806411 35798153 random_forest.cc:811] Training of tree  101/200 (tree index:100) done rmse:0.138464\n",
      "I0000 00:00:1736216889.898018 35798153 random_forest.cc:811] Training of tree  111/200 (tree index:110) done rmse:0.13818\n",
      "I0000 00:00:1736216889.991361 35798153 random_forest.cc:811] Training of tree  121/200 (tree index:120) done rmse:0.138369\n",
      "I0000 00:00:1736216890.086831 35798153 random_forest.cc:811] Training of tree  131/200 (tree index:130) done rmse:0.137788\n",
      "I0000 00:00:1736216890.178749 35798153 random_forest.cc:811] Training of tree  141/200 (tree index:140) done rmse:0.137706\n",
      "I0000 00:00:1736216890.271497 35798153 random_forest.cc:811] Training of tree  151/200 (tree index:150) done rmse:0.137348\n",
      "I0000 00:00:1736216890.366223 35798153 random_forest.cc:811] Training of tree  161/200 (tree index:160) done rmse:0.137273\n",
      "I0000 00:00:1736216890.458811 35798153 random_forest.cc:811] Training of tree  171/200 (tree index:170) done rmse:0.137551\n",
      "I0000 00:00:1736216890.553588 35798153 random_forest.cc:811] Training of tree  181/200 (tree index:180) done rmse:0.137434\n",
      "I0000 00:00:1736216890.645988 35798153 random_forest.cc:811] Training of tree  191/200 (tree index:190) done rmse:0.137046\n",
      "I0000 00:00:1736216890.728533 35798153 random_forest.cc:811] Training of tree  200/200 (tree index:199) done rmse:0.136888\n",
      "I0000 00:00:1736216890.728586 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.136888\n",
      "2025-01-06 21:28:10.775719: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [17/20] Score: -0.136888 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 200 } } fields { name: \"max_depth\" value { integer: 30 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "I0000 00:00:1736216890.776133 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216890.782257 35798206 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.242077\n",
      "I0000 00:00:1736216890.827525 35798206 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.170155\n",
      "I0000 00:00:1736216890.872208 35798206 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.154426\n",
      "I0000 00:00:1736216890.917509 35798206 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.149442\n",
      "I0000 00:00:1736216890.961537 35798206 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.146052\n",
      "I0000 00:00:1736216891.006749 35798206 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.144447\n",
      "I0000 00:00:1736216891.052116 35798206 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.143415\n",
      "I0000 00:00:1736216891.097641 35798206 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.142205\n",
      "I0000 00:00:1736216891.143969 35798206 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.141254\n",
      "I0000 00:00:1736216891.189010 35798206 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.140485\n",
      "I0000 00:00:1736216891.234241 35798206 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.140561\n",
      "I0000 00:00:1736216891.279878 35798206 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.140352\n",
      "I0000 00:00:1736216891.325902 35798206 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.140058\n",
      "I0000 00:00:1736216891.369589 35798206 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.13999\n",
      "I0000 00:00:1736216891.414232 35798206 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.139964\n",
      "I0000 00:00:1736216891.458788 35798206 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.139764\n",
      "I0000 00:00:1736216891.503978 35798206 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.139362\n",
      "I0000 00:00:1736216891.548585 35798206 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.139423\n",
      "I0000 00:00:1736216891.598566 35798206 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.139598\n",
      "I0000 00:00:1736216891.647658 35798206 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.139395\n",
      "I0000 00:00:1736216891.693123 35798206 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.139068\n",
      "I0000 00:00:1736216891.737499 35798206 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.139134\n",
      "I0000 00:00:1736216891.781775 35798206 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.138897\n",
      "I0000 00:00:1736216891.855680 35798206 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.138607\n",
      "I0000 00:00:1736216891.901209 35798206 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.138499\n",
      "I0000 00:00:1736216891.945870 35798206 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.138467\n",
      "I0000 00:00:1736216891.990830 35798206 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.138553\n",
      "I0000 00:00:1736216892.034738 35798206 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.138595\n",
      "I0000 00:00:1736216892.080218 35798206 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.138547\n",
      "I0000 00:00:1736216892.126232 35798206 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.138178\n",
      "I0000 00:00:1736216892.170910 35798206 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.138316\n",
      "I0000 00:00:1736216892.214328 35798206 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.138262\n",
      "I0000 00:00:1736216892.258855 35798206 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.138151\n",
      "I0000 00:00:1736216892.304337 35798206 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.13781\n",
      "I0000 00:00:1736216892.350900 35798206 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.137869\n",
      "I0000 00:00:1736216892.395457 35798206 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.137888\n",
      "I0000 00:00:1736216892.445818 35798206 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.137967\n",
      "I0000 00:00:1736216892.508335 35798206 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.13793\n",
      "I0000 00:00:1736216892.554328 35798206 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.138033\n",
      "I0000 00:00:1736216892.600761 35798206 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.137923\n",
      "I0000 00:00:1736216892.645391 35798206 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.137801\n",
      "I0000 00:00:1736216892.691138 35798206 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.137731\n",
      "I0000 00:00:1736216892.737527 35798206 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.137852\n",
      "I0000 00:00:1736216892.784706 35798206 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.137805\n",
      "I0000 00:00:1736216892.830654 35798206 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.137688\n",
      "I0000 00:00:1736216892.875611 35798206 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.137736\n",
      "I0000 00:00:1736216892.920606 35798206 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.137772\n",
      "I0000 00:00:1736216892.965290 35798206 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.137775\n",
      "I0000 00:00:1736216893.010614 35798206 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.137843\n",
      "I0000 00:00:1736216893.056631 35798206 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.137778\n",
      "I0000 00:00:1736216893.105748 35798206 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.13774\n",
      "I0000 00:00:1736216893.105830 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.13774\n",
      "2025-01-06 21:28:13.149410: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [18/20] Score: -0.13774 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "I0000 00:00:1736216893.149726 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216893.156287 35798227 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.243654\n",
      "I0000 00:00:1736216893.199933 35798227 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.169583\n",
      "I0000 00:00:1736216893.243709 35798227 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.151559\n",
      "I0000 00:00:1736216893.288353 35798227 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.146799\n",
      "I0000 00:00:1736216893.333868 35798227 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.145226\n",
      "I0000 00:00:1736216893.375944 35798227 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.143948\n",
      "I0000 00:00:1736216893.418961 35798227 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.143648\n",
      "I0000 00:00:1736216893.463098 35798227 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.143092\n",
      "I0000 00:00:1736216893.507776 35798227 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.142386\n",
      "I0000 00:00:1736216893.552920 35798227 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.142159\n",
      "I0000 00:00:1736216893.597792 35798227 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.141564\n",
      "I0000 00:00:1736216893.643086 35798227 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.141439\n",
      "I0000 00:00:1736216893.688384 35798227 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.141118\n",
      "I0000 00:00:1736216893.731883 35798227 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.141301\n",
      "I0000 00:00:1736216893.775970 35798227 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.140865\n",
      "I0000 00:00:1736216893.820302 35798227 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.140624\n",
      "I0000 00:00:1736216893.864238 35798227 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.139869\n",
      "I0000 00:00:1736216893.908914 35798227 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.139589\n",
      "I0000 00:00:1736216893.953056 35798227 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.139628\n",
      "I0000 00:00:1736216893.996468 35798227 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.139442\n",
      "I0000 00:00:1736216894.040282 35798227 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.139406\n",
      "I0000 00:00:1736216894.084660 35798227 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.139422\n",
      "I0000 00:00:1736216894.128793 35798227 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.139417\n",
      "I0000 00:00:1736216894.172661 35798227 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.138988\n",
      "I0000 00:00:1736216894.215656 35798227 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.138863\n",
      "I0000 00:00:1736216894.258739 35798227 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.138772\n",
      "I0000 00:00:1736216894.302939 35798227 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.138605\n",
      "I0000 00:00:1736216894.346991 35798227 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.138432\n",
      "I0000 00:00:1736216894.391171 35798227 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.138562\n",
      "I0000 00:00:1736216894.435090 35798227 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.138398\n",
      "I0000 00:00:1736216894.478485 35798227 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.138494\n",
      "I0000 00:00:1736216894.522399 35798227 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.138461\n",
      "I0000 00:00:1736216894.566990 35798227 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.138402\n",
      "I0000 00:00:1736216894.611360 35798227 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.13829\n",
      "I0000 00:00:1736216894.656007 35798227 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.138185\n",
      "I0000 00:00:1736216894.699750 35798227 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.138255\n",
      "I0000 00:00:1736216894.742483 35798227 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.138223\n",
      "I0000 00:00:1736216894.785984 35798227 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.138175\n",
      "I0000 00:00:1736216894.831415 35798227 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.138036\n",
      "I0000 00:00:1736216894.881938 35798227 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.137937\n",
      "I0000 00:00:1736216894.926614 35798227 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.137997\n",
      "I0000 00:00:1736216894.970281 35798227 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.137937\n",
      "I0000 00:00:1736216895.014673 35798227 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.137984\n",
      "I0000 00:00:1736216895.057973 35798227 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.13814\n",
      "I0000 00:00:1736216895.102463 35798227 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.138219\n",
      "I0000 00:00:1736216895.145632 35798227 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.138323\n",
      "I0000 00:00:1736216895.189470 35798227 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.138315\n",
      "I0000 00:00:1736216895.232887 35798227 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.138309\n",
      "I0000 00:00:1736216895.276817 35798227 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.1383\n",
      "I0000 00:00:1736216895.321569 35798227 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.138255\n",
      "I0000 00:00:1736216895.362004 35798227 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.138225\n",
      "I0000 00:00:1736216895.362052 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.138225\n",
      "2025-01-06 21:28:15.389518: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [19/20] Score: -0.138225 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: 10 } } fields { name: \"min_examples\" value { integer: 5 } }\n",
      "I0000 00:00:1736216895.389844 35797558 random_forest.cc:427] Training random forest on 1165 example(s) and 80 feature(s).\n",
      "I0000 00:00:1736216895.401383 35798291 random_forest.cc:811] Training of tree  1/500 (tree index:0) done rmse:0.237098\n",
      "I0000 00:00:1736216895.493529 35798291 random_forest.cc:811] Training of tree  11/500 (tree index:10) done rmse:0.164751\n",
      "I0000 00:00:1736216895.584291 35798291 random_forest.cc:811] Training of tree  21/500 (tree index:20) done rmse:0.151227\n",
      "I0000 00:00:1736216895.677704 35798291 random_forest.cc:811] Training of tree  31/500 (tree index:30) done rmse:0.145731\n",
      "I0000 00:00:1736216895.770350 35798291 random_forest.cc:811] Training of tree  41/500 (tree index:40) done rmse:0.142523\n",
      "I0000 00:00:1736216895.863547 35798291 random_forest.cc:811] Training of tree  51/500 (tree index:50) done rmse:0.140763\n",
      "I0000 00:00:1736216895.955986 35798291 random_forest.cc:811] Training of tree  61/500 (tree index:60) done rmse:0.140082\n",
      "I0000 00:00:1736216896.047772 35798291 random_forest.cc:811] Training of tree  71/500 (tree index:70) done rmse:0.139441\n",
      "I0000 00:00:1736216896.140124 35798291 random_forest.cc:811] Training of tree  81/500 (tree index:80) done rmse:0.139432\n",
      "I0000 00:00:1736216896.231354 35798291 random_forest.cc:811] Training of tree  91/500 (tree index:90) done rmse:0.139005\n",
      "I0000 00:00:1736216896.323500 35798291 random_forest.cc:811] Training of tree  101/500 (tree index:100) done rmse:0.138464\n",
      "I0000 00:00:1736216896.416552 35798291 random_forest.cc:811] Training of tree  111/500 (tree index:110) done rmse:0.13818\n",
      "I0000 00:00:1736216896.509317 35798291 random_forest.cc:811] Training of tree  121/500 (tree index:120) done rmse:0.138369\n",
      "I0000 00:00:1736216896.601475 35798291 random_forest.cc:811] Training of tree  131/500 (tree index:130) done rmse:0.137788\n",
      "I0000 00:00:1736216896.702382 35798291 random_forest.cc:811] Training of tree  141/500 (tree index:140) done rmse:0.137706\n",
      "I0000 00:00:1736216896.794598 35798291 random_forest.cc:811] Training of tree  151/500 (tree index:150) done rmse:0.137348\n",
      "I0000 00:00:1736216896.887303 35798291 random_forest.cc:811] Training of tree  161/500 (tree index:160) done rmse:0.137273\n",
      "I0000 00:00:1736216896.980306 35798291 random_forest.cc:811] Training of tree  171/500 (tree index:170) done rmse:0.137551\n",
      "I0000 00:00:1736216897.072420 35798291 random_forest.cc:811] Training of tree  181/500 (tree index:180) done rmse:0.137434\n",
      "I0000 00:00:1736216897.165274 35798291 random_forest.cc:811] Training of tree  191/500 (tree index:190) done rmse:0.137046\n",
      "I0000 00:00:1736216897.257856 35798291 random_forest.cc:811] Training of tree  201/500 (tree index:200) done rmse:0.136905\n",
      "I0000 00:00:1736216897.348674 35798291 random_forest.cc:811] Training of tree  211/500 (tree index:210) done rmse:0.136918\n",
      "I0000 00:00:1736216897.442630 35798291 random_forest.cc:811] Training of tree  221/500 (tree index:220) done rmse:0.136892\n",
      "I0000 00:00:1736216897.534307 35798291 random_forest.cc:811] Training of tree  231/500 (tree index:230) done rmse:0.13665\n",
      "I0000 00:00:1736216897.626096 35798291 random_forest.cc:811] Training of tree  241/500 (tree index:240) done rmse:0.136462\n",
      "I0000 00:00:1736216897.719740 35798291 random_forest.cc:811] Training of tree  251/500 (tree index:250) done rmse:0.13666\n",
      "I0000 00:00:1736216897.811520 35798291 random_forest.cc:811] Training of tree  261/500 (tree index:260) done rmse:0.136485\n",
      "I0000 00:00:1736216897.902707 35798291 random_forest.cc:811] Training of tree  271/500 (tree index:270) done rmse:0.136472\n",
      "I0000 00:00:1736216897.995994 35798291 random_forest.cc:811] Training of tree  281/500 (tree index:280) done rmse:0.136398\n",
      "I0000 00:00:1736216898.087832 35798291 random_forest.cc:811] Training of tree  291/500 (tree index:290) done rmse:0.136288\n",
      "I0000 00:00:1736216898.178862 35798291 random_forest.cc:811] Training of tree  301/500 (tree index:300) done rmse:0.136434\n",
      "I0000 00:00:1736216898.273310 35798291 random_forest.cc:811] Training of tree  311/500 (tree index:310) done rmse:0.136454\n",
      "I0000 00:00:1736216898.366028 35798291 random_forest.cc:811] Training of tree  321/500 (tree index:320) done rmse:0.136363\n",
      "I0000 00:00:1736216898.457984 35798291 random_forest.cc:811] Training of tree  331/500 (tree index:330) done rmse:0.136143\n",
      "I0000 00:00:1736216898.553148 35798291 random_forest.cc:811] Training of tree  341/500 (tree index:340) done rmse:0.136292\n",
      "I0000 00:00:1736216898.653985 35798291 random_forest.cc:811] Training of tree  351/500 (tree index:350) done rmse:0.136282\n",
      "I0000 00:00:1736216898.745202 35798291 random_forest.cc:811] Training of tree  361/500 (tree index:360) done rmse:0.136268\n",
      "I0000 00:00:1736216898.838460 35798291 random_forest.cc:811] Training of tree  371/500 (tree index:370) done rmse:0.136394\n",
      "I0000 00:00:1736216898.930064 35798291 random_forest.cc:811] Training of tree  381/500 (tree index:380) done rmse:0.136362\n",
      "I0000 00:00:1736216899.020431 35798291 random_forest.cc:811] Training of tree  391/500 (tree index:390) done rmse:0.136388\n",
      "I0000 00:00:1736216899.112807 35798291 random_forest.cc:811] Training of tree  401/500 (tree index:400) done rmse:0.136114\n",
      "I0000 00:00:1736216899.205683 35798291 random_forest.cc:811] Training of tree  411/500 (tree index:410) done rmse:0.135983\n",
      "I0000 00:00:1736216899.297173 35798291 random_forest.cc:811] Training of tree  421/500 (tree index:420) done rmse:0.135966\n",
      "I0000 00:00:1736216899.389704 35798291 random_forest.cc:811] Training of tree  431/500 (tree index:430) done rmse:0.135944\n",
      "I0000 00:00:1736216899.483780 35798291 random_forest.cc:811] Training of tree  441/500 (tree index:440) done rmse:0.135909\n",
      "I0000 00:00:1736216899.575633 35798291 random_forest.cc:811] Training of tree  451/500 (tree index:450) done rmse:0.136028\n",
      "I0000 00:00:1736216899.668737 35798291 random_forest.cc:811] Training of tree  461/500 (tree index:460) done rmse:0.135966\n",
      "I0000 00:00:1736216899.760127 35798291 random_forest.cc:811] Training of tree  471/500 (tree index:470) done rmse:0.135929\n",
      "I0000 00:00:1736216899.850866 35798291 random_forest.cc:811] Training of tree  481/500 (tree index:480) done rmse:0.135933\n",
      "I0000 00:00:1736216899.945262 35798291 random_forest.cc:811] Training of tree  491/500 (tree index:490) done rmse:0.135803\n",
      "I0000 00:00:1736216900.027961 35798291 random_forest.cc:811] Training of tree  500/500 (tree index:499) done rmse:0.135769\n",
      "I0000 00:00:1736216900.028015 35797558 random_forest.cc:891] Final OOB metrics: rmse:0.135769\n",
      "2025-01-06 21:28:20.143882: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:578] [20/20] Score: -0.135769 / -0.135769 HParams: fields { name: \"num_trees\" value { integer: 500 } } fields { name: \"max_depth\" value { integer: -1 } } fields { name: \"min_examples\" value { integer: 2 } }\n",
      "2025-01-06 21:28:20.183078: I external/ydf/yggdrasil_decision_forests/learner/hyperparameters_optimizer/hyperparameters_optimizer.cc:219] Best hyperparameters:\n",
      "fields {\n",
      "  name: \"num_trees\"\n",
      "  value {\n",
      "    integer: 500\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  value {\n",
      "    integer: 30\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  value {\n",
      "    integer: 2\n",
      "  }\n",
      "}\n",
      "\n",
      "I0000 00:00:1736216900.183203 35797557 kernel.cc:926] Export model in log directory: /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpqkkn4nb2 with prefix 9ee7417c41cb4b54\n",
      "I0000 00:00:1736216900.328723 35797557 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1736216900.329550 35735652 abstract_model.cc:914] Model self evaluation:\n",
      "Number of predictions (without weights): 1165\n",
      "Number of predictions (with weights): 1165\n",
      "Task: REGRESSION\n",
      "Label: __LABEL\n",
      "\n",
      "RMSE: 0.135769 CI95[X2][0.130473 0.141516]\n",
      "Default RMSE: : 0.398999\n",
      "\n",
      "2025-01-06 21:28:20.396928: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/dw/bq4phr0s4yz1_3vy2_gppjcm0000gp/T/tmpqkkn4nb2/model/ with prefix 9ee7417c41cb4b54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:37.539297\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736216900.937911 35735652 decision_forest.cc:761] Model loaded with 500 root(s), 448772 node(s), and 79 input feature(s).\n",
      "I0000 00:00:1736216900.937938 35735652 abstract_model.cc:1404] Engine \"RandomForestOptPred\" built\n",
      "2025-01-06 21:28:20.937951: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train each model\n",
    "for model_name, config in params.items():\n",
    "    output_logs.append(f\"Training and tuning {model_name}...\")\n",
    "\n",
    "    num_trial = num_trials.get(model_name, 10)  # Get the number of trials for the model\n",
    "    tuner = tfdf.tuner.RandomSearch(num_trials=num_trial)\n",
    "    \n",
    "    # Loop through the configuration dictionary and set the hyperparameters\n",
    "    for param, values in config.items():\n",
    "        tuner.choice(param, values)\n",
    "    \n",
    "    model_class = models[model_name]  # Get the corresponding model class\n",
    "    model = model_class(task=tfdf.keras.Task.REGRESSION, tuner=tuner)\n",
    "    \n",
    "    model.fit(train_ds)\n",
    "\n",
    "    #get best parameters\n",
    "    tuning_logs = model.make_inspector().tuning_logs()\n",
    "    best_params = tuning_logs[tuning_logs.best].iloc[0]\n",
    "    \n",
    "    predictions_log = model.predict(test_ds)\n",
    "    y_pred = np.exp(predictions_log)\n",
    "    y_true = np.exp(y_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    output_logs.append(f\"Best parameters for {model_name}: {best_params}\")\n",
    "    output_logs.append(f\"Best RMSE for {model_name}: {rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e833c89c-e184-45ea-9a67-e08655945c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning gradient_boosted_trees...\n",
      "Best parameters for gradient_boosted_trees: score             -0.140887\n",
      "evaluation_time    1.378276\n",
      "best                   True\n",
      "num_trees               200\n",
      "shrinkage               0.3\n",
      "max_depth                 6\n",
      "min_examples              5\n",
      "Name: 6, dtype: object\n",
      "Best RMSE for gradient_boosted_trees: 27632.958822\n",
      "Training and tuning random_forest...\n",
      "Best parameters for random_forest: score              -0.135769\n",
      "evaluation_time    19.173921\n",
      "best                    True\n",
      "num_trees                500\n",
      "max_depth                 30\n",
      "min_examples               2\n",
      "Name: 11, dtype: object\n",
      "Best RMSE for random_forest: 30612.963812\n"
     ]
    }
   ],
   "source": [
    "for log in output_logs:\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e374d-acc2-48fe-8878-b58123c71bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
